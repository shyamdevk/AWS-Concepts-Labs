# â˜ï¸ Amazon Web Services (AWS)
![Docker GIF](aws.gif)

A well-structured guide covering **IAM, Roles, S3, Policies, Encryption, Replication, Lifecycle Rules, and VPC** â€” simplified for study and quick reference.

---

## ğŸ” AWS Identity and Access Management (IAM)

### ğŸ‘¤ IAM Limits
- **Users:** Up to `5000`
- **Groups:** Up to `300`
- **Managed Policies attached per entity:** Up to `10`

---

### ğŸ§¾ Types of Policies
1. **AWS Managed** â€” Managed by AWS  
2. **Customer Managed** â€” Created and managed by the user  

---

### ğŸ†” Amazon Resource Name (ARN)

**Example:**
```

arn:aws:iam::aws:policy/AmazonS3FullAccess

````

#### ğŸ”¹ Parts of the ARN:
| Part | Meaning |
|------|----------|
| `arn` | Amazon Resource Name |
| `aws` | AWS Partition (Standard Region) |
| `iam` | AWS Service (IAM) |
| `::` | No region (IAM is global) |
| `aws` | Owned by AWS (not your account) |
| `policy/AmazonS3FullAccess` | Specific policy name |

---

## ğŸ§± IAM Policies Example

### ğŸ¯ Allow & Deny Access to Buckets
```json
{
  "Version": "2012-10-17",
  "Statement": [
    {
      "Sid": "AllowAccessToBuckets",
      "Effect": "Allow",
      "Action": "s3:*",
      "Resource": [
        "arn:aws:s3:::bucket-677",
        "arn:aws:s3:::test-bucket-7988"
      ]
    },
    {
      "Sid": "DenyRestrictedBucket",
      "Effect": "Deny",
      "Action": "s3:*",
      "Resource": [
        "arn:aws:s3:::test-bucket-86786"
      ]
    }
  ]
}
````

---

### ğŸ“„ Inline Policy

* Created for a **specific user** (not reusable across groups).

---

### ğŸ§­ Types of IAM Policies

* Identity-based Policy
* Resource-based Policy
* Access Control List (ACL)
* Permission Boundaries
* Session Policy
* Organization Service Control Policy
* Organization Resource Control Policy

---

## ğŸ§° AWS Roles

### ğŸ¯ Purpose

* Grant **temporary access** using **STS (Security Token Service)**.
* Used for **cross-account access** or **temporary credentials**.

### âš™ï¸ Steps to Create Role

1. Create a Role & Assign Permissions
2. Create Inline Policy for the User

```json
{
  "Version": "2012-10-17",
  "Statement": [
    {
      "Sid": "Statement1",
      "Effect": "Allow",
      "Action": ["sts:AssumeRole"],
      "Resource": ["arn:aws:iam::526888234336:role/TempUse"]
    }
  ]
}
```

â¡ï¸ Then go to AWS Console â†’ **Switch Role** under your profile.

---

## ğŸ”„ Cross-Account Role Access

### ğŸ§© Goal

Allow your IAM user (Account A) to access your friendâ€™s AWS Account (Account B).

---

### ğŸ‘¥ Friendâ€™s Account (B)

1. Create Role â†’ Choose **Another AWS Account**
2. Enter **Your Account ID**
3. Attach Policies (e.g., `AmazonS3ReadOnlyAccess`)
4. Copy Role ARN:

```
arn:aws:iam::123456789012:role/CrossAccountAccessRole
```

---

### ğŸ‘¤ Your Account (A)

Attach Policy to your IAM User:

```json
{
  "Version": "2012-10-17",
  "Statement": [
    {
      "Effect": "Allow",
      "Action": "sts:AssumeRole",
      "Resource": "arn:aws:iam::123456789012:role/CrossAccountAccessRole"
    }
  ]
}
```

Then go to AWS Console â†’ **Switch Role**

---

## ğŸ–¥ï¸ EC2 â€” Launching Instance

1. Launch EC2 â†’ Configure resources (CPU, memory, key pair)
2. Create IAM Role (e.g., to access S3)
3. Attach Role:
   `Actions â†’ Security â†’ Modify IAM Role`
4. Connect via terminal:

   ```bash
   ssh -i "C:\path\Demo-KeyServer.pem" ec2-user@<PublicIP>
   ```
5. Example command:

   ```bash
   aws s3 ls
   ```
6. Terminate after use â†’ `Instance State â†’ Terminate`

---

## ğŸ§‘â€ğŸ’¼ AWS Identity Center (SSO) vs AWS Organizations

| Feature  | AWS Identity Center            | AWS Organizations               |
| -------- | ------------------------------ | ------------------------------- |
| Purpose  | Central user access management | Manage multiple AWS accounts    |
| Function | Single Sign-On (SSO)           | Group accounts & set policies   |
| Control  | IAM Role Assignments           | Service Control Policies (SCPs) |
| Billing  | Per user                       | Consolidated Billing            |

---

## ğŸª£ Amazon S3 (Simple Storage Service)

![AWS GIF](https://github.com/shyamdevk/AWS-Concepts-Labs/blob/images/s3.gif)


### âš™ï¸ Features

* Unlimited storage
* Auto-scalable
* Highly reliable
* Max upload: **160 GB (Console)**, **5 TB (CLI)**
* Use **Multipart Upload** for >5TB files

---

### ğŸ—‚ï¸ Storage Types

* **Block Storage** â†’ EBS
* **File Storage** â†’ EFS
* **Object Storage** â†’ S3

---

### ğŸ§¾ Bucket Types

1. General Purpose
2. Directory Bucket (Low latency)
3. Table Bucket (Tabular data)

---

### ğŸ’» CLI Commands

```bash
aws s3 ls                        # List Buckets
aws s3 mb s3://tempbuck0078      # Create Bucket
aws s3 rb s3://tempbuck0078 --force  # Delete Bucket
```

ğŸ”— [More S3 CLI Commands](https://docs.aws.amazon.com/cli/latest/index.html)

---

## ğŸ—ƒï¸ S3 Bucket Management

### ğŸ§¬ Versioning

* Prevent overwriting objects with the same name.
  **Types:**
* Versioned
* Unversioned
* Version Suspended

---

### ğŸŒ Access Object via URL

1. Enable ACLs
2. Disable â€œBlock Public Accessâ€
3. Make Object Public

---

## ğŸ›¡ï¸ Object Lock

* Implements **WORM (Write Once, Read Many)** model.
* Prevents deletion/modification for a set period.

### ğŸ•’ Retention Modes

* **Compliance Mode** â€” Even root canâ€™t delete
* **Governance Mode** â€” Admins can modify with special permissions
* **Legal Hold** â€” No expiry until removed

---

## ğŸ§© S3 ACL (Access Control List)

| Type       | Purpose       | Permissions                      |
| ---------- | ------------- | -------------------------------- |
| Bucket ACL | Whole bucket  | READ, WRITE, READ_ACP, WRITE_ACP |
| Object ACL | Single object | READ, READ_ACP, WRITE_ACP        |

---

## ğŸ“œ Server Access Logging

* Logs every action in a bucket.
* To avoid recursive logs, store them in a **destination bucket**.

âœ… Steps:

1. Create destination bucket
2. Enable logging in **source bucket (Properties tab)**
3. Check `.log` files in destination bucket

---

## ğŸ”’ S3 Encryption

### ğŸ§  Types

| Type        | Where It Happens  | Key Managed By |
| ----------- | ----------------- | -------------- |
| Client-side | Before upload     | You            |
| SSE-S3      | In S3             | AWS            |
| SSE-KMS     | In S3             | KMS            |
| DSSE-KMS    | Dual KMS keys     | AWS KMS        |
| SSE-C       | Customer-provided | You            |

---

## ğŸ“„ Bucket Policy Example

Make all objects public:

```json
{
  "Version": "2012-10-17",
  "Statement": [
    {
      "Sid": "PublicReadGetObject",
      "Effect": "Allow",
      "Principal": "*",
      "Action": "s3:GetObject",
      "Resource": "arn:aws:s3:::my-example-bucket/*"
    }
  ]
}
```

---

## ğŸ” Replication

* **CRR (Cross-Region Replication):** Between regions
* **SRR (Same-Region Replication):** Within same region
* **Cross-Account Replication:** Between different accounts

---

## âš™ï¸ S3 Batch Operations

Perform bulk operations:

* Copy objects
* Modify tags or ACLs
* Trigger Lambda for each object

---

## ğŸ  S3 Outposts

* Run S3 locally on AWS Outposts hardware.

---

## ğŸ§® Storage Classes & Lifecycle

### ğŸ—‚ï¸ Frequent Access

* **S3 Standard**
* **S3 Express One Zone**
* **Reduced Redundancy (RRS)**

### ğŸ•“ Infrequent Access

* **Standard-IA**
* **One Zone-IA**

### ğŸ“¦ Archive

* **Glacier Instant Retrieval**
* **Glacier Flexible Retrieval**
* **Glacier Deep Archive**

### ğŸ¤– Intelligent-Tiering

Automatically moves data between:

* Frequent Access
* Infrequent Access
* Archive Tiers

---

## â³ Lifecycle Configuration

**Two actions:**

* **Transition** â†’ Move to cheaper storage
* **Expiration** â†’ Delete after time period

âœ… Steps:

1. Open bucket â†’ **Management tab**
2. Create rule â†’ Define transitions & expiration

---

## ğŸ”” S3 Event Notification

Triggers alerts for:

* Object created
* Object deleted
* Metadata changes

---

## âš¡ S3 Transfer Acceleration

* Uses CloudFront Edge locations for faster uploads/downloads.

---

## ğŸ’° S3 Requester Pays

* Requester pays download & data transfer costs, not bucket owner.

---

## ğŸŒ VPC (Virtual Private Cloud)

![AWS GIF](https://github.com/shyamdevk/AWS-Concepts-Labs/blob/images/vpc.gif)

A **private, isolated network** inside AWS.

### ğŸ”¹ Key Features:

* Define IP range (CIDR)
* Create public/private subnets
* Manage routing via route tables
* Secure via Security Groups & Network ACLs
* Internet access via **Internet Gateway**

---

## ğŸ’» EC2 via CMD

Connect to EC2 from Windows CMD:

```bash
ssh -i "C:\Users\shyam\Documents\Demo-KeyServer.pem" ec2-user@54.210.154.178
```

> âš ï¸ If connection fails, edit **Inbound Rules** of Security Group to allow SSH (port 22).

---

## ğŸ§  Kernel & CLI Essentials

### âš™ï¸ What is a Kernel?
> The **kernel** is the core component of an operating system.  
It acts as a **bridge between hardware and software**, managing communication between the two.
> ![Docker Initialization](https://media.geeksforgeeks.org/wp-content/uploads/20250124124411692602/kernel.webp)


---

## ğŸ’» Common CLI Commands

| Command | Description |
|----------|--------------|
| `whoami` | Display current username |
| `echo $0` | Show current shell type |
| `ls` | List files and folders |
| `mkdir <dir>` | Create a new directory |
| `Ctrl + L` | Clear CLI window |
| `cd` | Change directory |
| `pwd` | Show current working directory |
| `cd ..` | Go back to previous directory |
| `touch <file>` | Create an empty file |
| `rmdir <dir>` | Delete a directory |
| `rm *` | Remove all files and directories |
| `mkdir name1 name2` | Create 2 directories instantly |
| `mkdir folder{1..100}` | Create 100 folders instantly |
| `rmdir folder{1..100}` | Delete 100 folders instantly |
| `touch file1 file2` | Create multiple empty files |
| `rm -rf *` | Force delete all files/folders |
| `ls -a` | Show hidden files |
| `ll` | Detailed list of files and permissions |

---

## ğŸ“ Text Editors

### ğŸ§© Using VI Editor

Two modes in VI:
1. **Command Mode** â†’ Press `Esc`
2. **Insert Mode** â†’ Press `i`

#### Editing and Saving
```bash
i                # Enter insert mode
<Esc>            # Go back to command mode
:wq              # Save and exit
cat filename     # View file content
````

---

### ğŸ§  Using NANO Editor

```bash
touch demo.txt
nano demo.txt
# Edit the content
Ctrl + O + Enter  # Save
Ctrl + X          # Exit
```

---

## ğŸ‘¤ User Management (Linux)

### ğŸ§± Create a New User

```bash
sudo su
adduser <username>
```

### ğŸ”‘ Set Password

```bash
passwd <username>
```

### ğŸ”„ Switch to Root

```bash
sudo su
```

### ğŸ§­ List All Users

```bash
sudo su
cd /
cd etc/
cat passwd
```

---

### âš™ï¸ Sudoers Access (Root Privileges)

If new user cannot switch to root:

```bash
usermod -aG wheel <username>
sudo su
```

---

## ğŸ”’ Permissions & Ownership

### View Permissions

Example:

```
drwxr-xr-x. 2 ec2-user ec2-user 6 Aug 26 06:03 test
```

| Symbol | Meaning                   |
| ------ | ------------------------- |
| d      | Directory (if â€œ-â€ â†’ file) |
| rwx    | Read, Write, Execute      |
| r-x    | Read, Execute (no write)  |

---

### ğŸ”§ Modify Permissions

```bash
chmod 777 test
```

| Number | Meaning | Permissions |
| ------ | ------- | ----------- |
| 7      | 4+2+1   | rwx (full)  |
| 6      | 4+2     | rw-         |
| 5      | 4+1     | r-x         |
| 4      | 4       | r--         |
| 0      | 0       | ---         |

Example:

```
chmod 755 folder
```

---

### ğŸ‘‘ Change Ownership

```bash
sudo chown <user> <directory>
```

---

## ğŸ§± VPC (Virtual Private Cloud)

> A **VPC** is a private, isolated network inside AWS where you can launch and control resources securely.

---

### ğŸ§© STEP 1 â€” CREATE A VPC

**CIDR Block:** Defines a range of IP addresses for your VPC and subnets.
ğŸ§® Use calculator: [Subnet Calculator](https://www.davidc.net/sites/default/subnets/subnets.html)

#### ğŸ§  Components of VPC

1. **VPC:** Virtual network to host AWS resources.
2. **Subnets:** Segments of your IP range.

   * **Public Subnet** â†’ Connected to Internet Gateway.
   * **Private Subnet** â†’ No direct Internet access.
3. **Internet Gateway (IGW):** Enables internet connectivity.
4. **Route Table:** Controls traffic routing (to IGW or NAT).

---

### ğŸ§© STEP 2 â€” CREATE SUBNETS

* Go to **Subnets tab** â†’ Create subnet.
* Select your VPC.
* Assign name and **CIDR Block**.
* When VPC is created â†’ AWS auto-creates:

  * Main Route Table
  * Network ACL
  * DHCP Options Set
  * Default Security Group

#### âš ï¸ Reserved IPs in Subnet

| IP Address | Usage             |
| ---------- | ----------------- |
| 10.0.0.0   | Network Address   |
| 10.0.0.1   | VPC Router        |
| 10.0.0.2   | DNS Address       |
| 10.0.0.3   | Future Use        |
| 10.0.0.127 | Broadcast Address |

---

### ğŸŒ STEP 3 â€” CREATE INTERNET GATEWAY

1. Go to **Internet Gateways tab** â†’ Create IGW
2. Attach to existing VPC via **Actions â†’ Attach to VPC**

---

### ğŸ›£ï¸ STEP 4 â€” ROUTE TABLE CONFIGURATION

1. Go to **Route Tables**
2. Select your VPCâ€™s route table
3. Add route:

   ```
   Destination: 0.0.0.0/0
   Target: Your Internet Gateway (IGW)
   ```
4. Use **Resource Map** to visualize connections.

---

### ğŸ’» STEP 5 â€” ATTACH VPC TO EC2

* While launching EC2 instance:

  * Under **Network Settings**, select your VPC & Subnet.
  * Enable Auto-assign Public IP.
  * Assign appropriate Security Group.
  * Launch instance.

---

### ğŸ–¥ï¸ STEP 6 â€” CLI CONNECTION

```bash
ssh -i "C:\Users\shyam\Downloads\Test-Server-Key.pem" ec2-user@67.202.33.11
# If timeout â†’ modify Security Group inbound rules for SSH (port 22)
```

---

### ğŸ”’ STEP 7 â€” MAKE SUBNET PRIVATE

* Create **new Route Table**.
* Associate only **private subnet** with this new route table.
* Verify via **Resource Map**.

---

### ğŸ” STEP 8 â€” CONNECT TO PRIVATE SERVER

1. SSH into **Public Server** first.
2. Copy your private key content into a file (using `vi`).
3. Save and set permission:

   ```bash
   chmod 700 <keyfile>
   ssh -i <keyfile> ec2-user@<PrivateIP>
   ```

âœ… Youâ€™re now connected to the private server via public instance.

> âš ï¸ Note: Public server must have internet access (IGW route in Route Table).
![Docker Initialization](gg.png)

---
# â˜ï¸ AWS Networking â€” NAT, Elastic IP, Firewall, and VPC Peering

> A complete guide to **AWS networking components** including **NAT Gateway**, **Elastic IP**, **NACLs**, **Security Groups**, and **VPC Peering Lifecycle**.  
> Simplified and ready for study or documentation.

---

## ğŸŒ NAT (Network Address Translation)

In AWS, **NAT** allows instances in a **private subnet** to access the **internet** (for updates, APIs, etc.) without exposing them to inbound internet traffic.

### ğŸ’¡ Use Case
Private servers can **download updates** via NAT Gateway,  
but **remain inaccessible** from the internet.

---

### âš™ï¸ Steps to Access Internet from Private Server via NAT

1. Create a **NAT Gateway** from the VPC console  
2. Select your **Public Subnet**  
3. Allocate an **Elastic IP**  
4. Create the **NAT Gateway**  
5. Assign the NAT Gateway to **Private Route Table**  
6. Add a new route:
   - **Destination:** `0.0.0.0/0`
   - **Target:** NAT Gateway

âœ… Done! Private instances now have **outbound internet access** without being exposed publicly.

---

## ğŸŒ Elastic IP (EIP)

An **Elastic IP (EIP)** is a **static, public IPv4 address** that stays permanently allocated to your AWS account.

### ğŸ“Œ Key Points

- **Static:** Unlike normal public IPs (which change when you stop/start an instance), an EIP **remains the same**.  
- **Re-mappable:** You can detach it from one instance and attach it to another â€” useful for **failover or recovery**.  
- **Purpose:** Provides a **permanent and consistent** public IP for EC2 instances or other resources.

---

### âš™ï¸ Steps to Allocate and Manage Elastic IP

1. Go to **VPC â†’ Elastic IPs â†’ Allocate Elastic IP Address**
2. Once allocated â†’ **Actions â†’ Associate Elastic IP**
3. Select the **EC2 instance** and **Save**
4. After use:
   - **Disassociate** the IP  
   - **Release** it from your account  

---

## ğŸ”¥ Firewall in VPC

AWS VPC provides **two firewall layers** to control inbound and outbound traffic.

| Firewall Type | Level | Stateful | Description |
|----------------|--------|-----------|--------------|
| **Network ACL (NACL)** | Subnet-level | âŒ Stateless | Controls subnet traffic using numbered rules |
| **Security Group** | Instance-level | âœ… Stateful | Controls inbound/outbound traffic for EC2 |

![Screenshot](https://github.com/shyamdevk/AWS-Concepts-Labs/blob/images/1.png)
---

## ğŸ§± Setting Up NACL (Network Access Control List)

### âš™ï¸ Steps:

1. Go to **VPC â†’ Network ACLs â†’ Create**
2. Select your **VPC**  
3. Under **Subnet Associations**, add the subnet(s) you want  
4. Add **Inbound** and **Outbound** rules (both mandatory)  
5. Remember:
   - Lower **Rule Number** = Higher priority  
   - `*` (asterisk) = Lowest priority
 ![Screenshot](https://github.com/shyamdevk/AWS-Concepts-Labs/blob/images/2.png)
 ![Screenshot](https://github.com/shyamdevk/AWS-Concepts-Labs/blob/images/3.png)

6. Outbound traffic should allow **All Traffic** for internet access

> ğŸš« Based on the configured rules and ports, the server traffic may be **allowed or denied**.

---

## ğŸ›¡ï¸ Setting Up Security Groups

### âš™ï¸ Steps:

1. Go to **VPC â†’ Security Groups â†’ Create Security Group**
2. Add **Inbound Rules** (Outbound rules are open by default)
  ![Screenshot](https://github.com/shyamdevk/AWS-Concepts-Labs/blob/images/4.png)
4. To attach:
   - EC2 â†’ **Actions â†’ Security â†’ Change Security Groups**
   - Remove the existing group  
   - Add your **new custom Security Group**

âœ… Security Groups are **stateful**, meaning return traffic is automatically allowed.

---

## ğŸ”¢ Port Numbers

| Type | Range | Description |
|-------|--------|-------------|
| **Total** | 0 â€“ 65535 | All available ports |
| **Well-known Ports** | 0 â€“ 1023 | Common services (HTTP, SSH, etc.) |
| **Registered Ports** | 1024 â€“ 49151 | User and system applications |
| **Dynamic Ports** | 49152 â€“ 65535 | Private/temporary connections |

---

## ğŸ” VPC Peering Connection Lifecycle

Below are the stages of a **VPC Peering Connection** in AWS.

![Screenshot](https://github.com/shyamdevk/AWS-Concepts-Labs/blob/images/5.png)


| State | Description |
|--------|--------------|
| **Initiating-request** | A VPC peering request is created by the requester |
| **Pending-acceptance** | Waiting for the accepter VPC to approve |
| **Active** | Peering successfully established |
| **Provisioning** | Connection setup in progress |
| **Deleting** | Connection is being removed |
| **Deleted** | Peering removed completely |
| **Failed** | Request could not be completed |
| **Expired** | Request not accepted in time |
| **Rejected** | Request denied by the accepter |
| **No longer visible** | Removed from console after failure/rejection |

---

## ğŸŒ‰ VPC Peering Connection

**Definition:**  
A **VPC Peering Connection** enables **two VPCs** to communicate using **private IP addresses**, making them appear as if theyâ€™re on the same internal network.

---

### âš™ï¸ STEP 1 â€” Create Two VPCs

1. **VPC A:** Public + Private Subnets  
2. **VPC B:** Private Subnet only  
3. AWS automatically creates:
   - Route Tables  
   - Internet Gateway  
   - Public & Private Subnets  

Example setup:
- **VPC A:** (Public + Private Subnets)  
- **VPC B:** (Private Subnet only)

---

### âš™ï¸ STEP 2 â€” Create EC2 Instances

1. Launch **3 EC2 Instances**
   - Instance 1 â†’ VPC A (Public Subnet)
   - Instance 2 â†’ VPC A (Private Subnet)
   - Instance 3 â†’ VPC B (Private Subnet)
     ![Screenshot](https://github.com/shyamdevk/AWS-Concepts-Labs/blob/images/6.png)

2. At this stage, **VPC A** and **VPC B** cannot communicate (no peering yet).

---

### âš™ï¸ STEP 3 â€” Create the Peering Connection

1. Go to **VPC â†’ Peering Connections â†’ Create**
2. **Requester:** VPC A (Public + Private)  
   **Accepter:** VPC B (Private only)
3. Once created â†’ Select Peering â†’ **Actions â†’ Accept Request**

---

### âš™ï¸ STEP 4 â€” Update Route Tables

- **Private Route Table (VPC A):**
  - Destination: CIDR range of VPC B
  - Target: Peering Connection
    ![Screenshot](https://github.com/shyamdevk/AWS-Concepts-Labs/blob/images/7.png)


- **Private Route Table (VPC B):**
  - Destination: CIDR range of VPC A
  - Target: Peering Connection  
 ![Screenshot](https://github.com/shyamdevk/AWS-Concepts-Labs/blob/images/8.png)

---

### âš™ï¸ STEP 5 â€” Configure Security Groups

- Go to **EC2 â†’ Security â†’ Edit Inbound Rules**
- Add **ICMP (Ping)** rule to allow communication between private instances  
  (used for testing connectivity)
![Screenshot](https://github.com/shyamdevk/AWS-Concepts-Labs/blob/images/9.png)

---

### âš™ï¸ STEP 6 â€” Verify Connection

From the **Private Instance in VPC A**, test connection to **Private Instance in VPC B:**
![Screenshot](https://github.com/shyamdevk/AWS-Concepts-Labs/blob/images/10.png)


```bash
ping <Private-IP-of-VPC-B-instance>
````

âœ… If ping succeeds, VPC Peering is active and functional.

---

## ğŸ§  Notes

* VPC Peering **across regions** requires **different key pairs**
* When peering **between AWS accounts**, copy the **VPC ID** of the peer account
* Both accounts must have at least **one public and one private subnet**
* Number of possible Peering Connections:

  ```
  n(n - 1) / 2
  ```

---

## ğŸ” Connection Flow Diagram (Text Representation)

```
JUMP SERVER (Public)
   â†“
PRIVATE SERVER (Same VPC)
   â†“
VPC PEERING CONNECTION
   â†“
PRIVATE SERVER (Another VPC)
```

---

## ğŸ§© Summary Table

| Component            | Purpose                                              |
| -------------------- | ---------------------------------------------------- |
| **NAT Gateway**      | Allows private instances to access internet securely |
| **Elastic IP (EIP)** | Static, public IPv4 address for instances            |
| **NACL**             | Subnet-level firewall (stateless)                    |
| **Security Group**   | Instance-level firewall (stateful)                   |
| **VPC Peering**      | Connects VPCs privately using internal IPs           |

---
# ğŸš AWS Transit Gateway (TGW) â€” Complete Guide

> Learn how to use **AWS Transit Gateway (TGW)** to connect multiple VPCs, on-premises networks, and regions seamlessly â€” all from a **central hub**.

---

## ğŸŒ What is a Transit Gateway?

![Screenshot](https://github.com/shyamdevk/AWS-Concepts-Labs/blob/images/11.png)


**Definition:**  
A **Transit Gateway (TGW)** is a **central hub** that connects multiple **VPCs**, **on-premises networks (via VPN or Direct Connect)**, and even **other AWS accounts**.  
It simplifies complex network architectures by acting as a single routing hub.

> âš ï¸ Transit Gateway works **only within the same AWS Region**, but supports **inter-region peering**.

---

## ğŸ•¸ï¸ Model: Hub-and-Spoke Architecture

- **Transit Gateway = Hub**  
- **VPCs / On-premises networks = Spokes**

Instead of connecting every VPC to every other VPC (full mesh), each connects only to the **TGW** â€” greatly reducing complexity.

---

## ğŸ¯ Purpose of Transit Gateway

- Replaces complex **VPC peering meshes**
- Simplifies connectivity between multiple VPCs or accounts
- Enables centralized **routing, monitoring, and security**

---

## âš™ï¸ Key Features

âœ… Centralized routing and traffic control  
âœ… Connects **thousands of VPCs**  
âœ… Simplifies management vs. multiple VPC peerings  
âœ… Highly scalable for large cloud networks  
âœ… Supports **inter-region peering** between TGWs  

---

## ğŸŒŸ Benefits

- **Simplified network design**  
- **Reduced complexity** (no need for many peerings)  
- **Centralized monitoring & control**  
- **Improved scalability and maintainability**

---

## ğŸ”Œ AWS Direct Connect

> **AWS Direct Connect** is a **dedicated private network connection** between your **on-premises data center** and **AWS**.

### ğŸ”¹ Features:
- Lower latency & higher bandwidth than internet-based VPN  
- Consistent and secure performance  
- Connects on-premises routers directly to AWS TGW or VPC  

---

# ğŸ§­ Tutorial: AWS Transit Gateway (Same Region Setup)

---

## ğŸ§© Step 1: Create Two VPCs

- **VPC-A:** Contains both **Public** and **Private** subnets  
- **VPC-B:** Contains only **Private** subnet  

> Each VPC will have its own route table and subnets.

---

## ğŸ–¥ï¸ Step 2: Launch EC2 Instances

- **Launch 3 instances total:**
  - 1 instance in **Public subnet (VPC-A)**
  - 2 instances in **Private subnets** (one in each VPC)

---

## ğŸŒ‰ Step 3: Create Transit Gateway

1. Go to **VPC â†’ Transit Gateways â†’ Create Transit Gateway**  
2. Add a **Name**  
3. State will initially appear as **Pending**

---

## ğŸ”— Step 4: Create TGW Attachments

1. Go to **VPC â†’ Transit Gateway Attachments**  
2. Choose your **TGW ID**  
3. Select **Attachment Type: VPC**  
4. Create **2 attachments** â€” one for each VPC (A and B)

---

## ğŸ›£ï¸ Step 5: Edit Route Tables

- **VPC-A (Private Route Table):**
  - Add route â†’ **Destination:** VPC-B CIDR  
  - **Target:** Transit Gateway
    ![Screenshot](https://github.com/shyamdevk/AWS-Concepts-Labs/blob/images/12.png)


- **VPC-B (Private Route Table):**
  - Add route â†’ **Destination:** VPC-A CIDR  
  - **Target:** Transit Gateway
![Screenshot](https://github.com/shyamdevk/AWS-Concepts-Labs/blob/images/13.png)
  

---

## ğŸ›¡ï¸ Step 6: Edit Security Groups

- Modify **Security Group** of the **destination (private)** instance  
- Add rule:
```

Type: ICMP
Protocol: Echo Request
Source: Other VPC CIDR Range

````

---

## ğŸ§ª Step 7: Verify Connectivity

From **VPC-Aâ€™s private instance**, test connection to **VPC-B**:
```bash
ping <Private-IP-of-VPC-B-instance>
````

âœ… Successful ping â†’ Transit Gateway connection is working!

---

# ğŸŒ Cross-Region Transit Gateway Peering Exercise

> Letâ€™s connect **two VPCs in different AWS regions** using **Transit Gateways** and **TGW Peering**.

---

## ğŸŒ Step 1: Create Two VPCs

* **VPC-A (North Virginia):** Contains **Public + Private** subnets â†’ (Requester)
* **VPC-B (Mumbai):** Contains **Private** subnet only â†’ (Accepter)

---

## ğŸ–¥ï¸ Step 2: Launch EC2 Instances

* Launch instances:

  * **2 instances in North Virginia**
  * **1 instance in Mumbai**

---

## ğŸš Step 3: Create Transit Gateways and Attachments

1. Create **Transit Gateway** in each region
2. Create attachments:

   * **VPC-A TGW:** 2 attachments (for both subnets)
   * **VPC-B TGW:** 1 attachment
3. For cross-region communication:

   * Create a **Peering Attachment** between both TGWs
   * Accept request from the **receiving region** (Mumbai)

> ğŸ§  Use â€œPeering Connectionâ€ as the **attachment type** during TGW setup.

![Screenshot](https://github.com/shyamdevk/AWS-Concepts-Labs/blob/images/14.png)


---

## ğŸ›£ï¸ Step 4: Transit Gateway Route Tables

* **Virginia TGW Route Table:**

  * Add route â†’ **Destination:** Mumbai VPC CIDR
  * **Target:** Peering Attachment

* **Mumbai TGW Route Table:**

  * Add route â†’ **Destination:** Virginia VPC CIDR
  * **Target:** Peering Attachment

---

## ğŸ§¾ Step 5: VPC Route Tables

* **Virginia Private Subnet Route Table:**

  * Destination â†’ Mumbai CIDR
  * Target â†’ Virginia TGW Attachment

* **Mumbai Private Subnet Route Table:**

  * Destination â†’ Virginia CIDR
  * Target â†’ Mumbai TGW Attachment

---

## ğŸ” Step 6: Security Groups

* **Mumbai Private EC2 Security Group:**

  * Allow **ICMP (ping)** from Virginia VPC CIDR

* **Virginia Private EC2 Security Group:**

  * Allow outbound (default `0.0.0.0/0` covers ICMP reply)

---

## ğŸ§© Step 7: Verify Connection

SSH into your **Virginia jump server**, then your **private instance**, and run:

```bash
ping <Mumbai-private-server-IP>
```

âœ… If ping succeeds, your **cross-region TGW peering** works correctly!

---

## ğŸ’» To SSH into Mumbai Server (via Virginia)

1. From **Virginia Private Server**, create a file using `vi`
2. Paste the **Mumbai key content** into it
3. Set permission:

   ```bash
   chmod 700 <keyfile>
   ```
4. Connect:

   ```bash
   ssh -i <keyfile> ec2-user@<Mumbai-Private-IP>
   ```

---

# ğŸ§  Key Takeaways

| Concept                   | Description                                  |
| ------------------------- | -------------------------------------------- |
| **Transit Gateway (TGW)** | Central hub for VPC and on-prem connectivity |
| **TGW Attachment**        | Connects a VPC or network to the TGW         |
| **TGW Peering**           | Connects TGWs across regions                 |
| **AWS Direct Connect**    | Dedicated on-premises to AWS link            |
| **Security Group (SG)**   | Instance-level firewall                      |
| **ICMP (Ping)**           | Used to verify private connectivity          |

---

> ğŸš€ **Pro Tip:**
> Transit Gateway is like AWSâ€™s **network backbone** â€” build once, and it scales to thousands of VPCs effortlessly.

# ğŸ§© AWS VPC Endpoints, Flow Logs, DNS Firewall & Managed Prefix Lists

> A complete guide covering **VPC Endpoints**, **VPC Flow Logs**, **DNS Firewall**, and **AWS Managed Prefix Lists** â€” simplified for learning and documentation.

---

## ğŸŒ VPC Endpoints

### ğŸ§  Definition

A **VPC Endpoint** enables a **private connection** between your VPC and **supported AWS services** (like S3, DynamoDB, etc.) â€” without needing:

- Internet Gateway (IGW)
- NAT Gateway
- VPN
- AWS Direct Connect

> âœ… All traffic stays **within the AWS network**, ensuring higher security and lower cost.

---

### ğŸŒŸ Benefits

| Feature | Description |
|----------|--------------|
| **Security** | No exposure to the public internet |
| **Cost** | Avoid NAT/IGW data transfer charges |
| **Performance** | Lower latency & higher reliability |

---

### ğŸ” Example Traffic Flow

| Without Endpoint | With Endpoint |
|-------------------|----------------|
| EC2 â†’ Internet Gateway/NAT â†’ Internet â†’ S3 | EC2 â†’ VPC Endpoint â†’ S3 (Private AWS Network) |

---

## ğŸ”¸ Types of VPC Endpoints

### 1ï¸âƒ£ Interface Endpoint
- Powered by **AWS PrivateLink**
- Creates an **ENI (Elastic Network Interface)** with a private IP inside your subnet
- Used for most AWS services (e.g., **CloudWatch**, **KMS**, **Secrets Manager**)

---

### 2ï¸âƒ£ Gateway Endpoint
- Adds an entry in **Route Tables**
- Used only for **Amazon S3** and **DynamoDB**

---

### 3ï¸âƒ£ Gateway Load Balancer Endpoint (GWLBe)
- Connects VPC traffic to **third-party network appliances** (e.g., firewalls, IDS/IPS)
- Ideal for **security and traffic inspection**

---

### 4ï¸âƒ£ Resource Endpoint
- Exposes a **specific resource** privately to another VPC
- Example: Share one **RDS Database** or **EC2 instance** across VPCs securely

---

### 5ï¸âƒ£ Service Network Endpoint
- Connects **multiple VPCs** to a **Service Network** via PrivateLink
- Useful when multiple VPCs need access to the same services centrally

---

# ğŸ§­ Tutorial: VPC Endpoints (Gateway Type)

### ğŸªœ Step 1 â€” Launch a VPC
- Create a VPC using **VPC â†’ VPC and More**

---

### ğŸªœ Step 2 â€” Configure Endpoint
1. Go to **VPC â†’ Endpoints â†’ Create Endpoint**
2. Choose **Type:** AWS Service  
3. Select the desired **Service** (e.g., S3)
![Screenshot](https://github.com/shyamdevk/AWS-Concepts-Labs/blob/images/15.png)
5. Choose your **VPC**
6. Select **Private Route Table**
7. Set **Policy:** Full Access

---

### ğŸªœ Step 3 â€” Launch EC2 Instances
- Launch 2 EC2 Instances:  
  - **Jump Server** (Public Subnet)  
  - **Private Server** (Private Subnet)

---

### ğŸªœ Step 4 â€” Attach Role to Private Server
1. Go to **EC2 â†’ Actions â†’ Security â†’ Modify IAM Role**
2. Choose **Create New Role**
3. Use Case â†’ **EC2**
4. Permission â†’ **S3 Full Access**

---

### ğŸªœ Step 5 â€” Verify Connection
1. Create an **S3 Bucket**
2. Connect:
   - Jump Server â†’ Private Server
3. Run command:
   ```bash
   aws s3 ls

## âœ… Using Interface Endpoint

### ğŸ”¹ Configuration Highlights

* Only the **Endpoint Type** changes â†’ Choose **Interface**
   ![Screenshot](https://github.com/shyamdevk/AWS-Concepts-Labs/blob/images/16.png)
* Select your **VPC**
* Enable **DNS Name**
* Disable **Private DNS for inbound endpoint**
 ![Screenshot](https://github.com/shyamdevk/AWS-Concepts-Labs/blob/images/17.png)
* Choose **Private Subnet**
* Select **Security Group** (default or custom)
* Policy: **Full Access**

After creation:

1. Edit the Endpointâ€™s **Security Group**  
   â†’ Add **Inbound Rule: HTTPS (443)**
   ![Screenshot](https://github.com/shyamdevk/AWS-Concepts-Labs/blob/images/18.png)
3. Connect to **Private Server** â†’ Run:
   ```bash
   aws s3 ls


âœ… Lists all existing S3 buckets using a **private connection** via Interface Endpoint.


# ğŸ§¾ VPC Flow Logs

### ğŸ§  Definition

**VPC Flow Logs** capture metadata about **IP traffic** going to and from network interfaces in your VPC.

They record:

* Source & Destination IPs
* Ports and Protocols
* Actions (ACCEPT / REJECT)
* Bytes transferred

Logs are stored in **CloudWatch Logs** or **S3** for visibility and analysis.

---

### ğŸ’¡ Use Cases

| Purpose               | Description                               |
| --------------------- | ----------------------------------------- |
| **Security Analysis** | Detect unusual or unauthorized traffic    |
| **Troubleshooting**   | Diagnose connectivity or routing issues   |
| **Monitoring**        | Track accepted and rejected network flows |

âœ… In short:

> **VPC Flow Logs = Network traffic audit inside your VPC**

---

## ğŸ§­ Tutorial: Create and Analyze VPC Flow Logs

### ğŸªœ Step 1 â€” Create Flow Logs

1. Open **VPC â†’ Select your VPC**
2. Go to **Flow Logs â†’ Create Flow Log**
3. Configure:

   * **Filter:** All / Accepted / Rejected
   * **Interval:** Choose logging interval
   * **Destination:** CloudWatch or S3
   * **Log Format & File Format**
4. Click **Create Flow Log**

---

### ğŸªœ Step 2 â€” Generate and View Logs

1. Launch an EC2 **Jump Server**
2. Generate network activity:

   ```bash
   ping google.com
   ```
3. Wait a few minutes
4. Check **S3 bucket** or **CloudWatch Logs**
5. Extract any `.zip` files and review the log metadata.

---

# ğŸ§± DNS Firewall (Amazon Route 53 Resolver)

### ğŸ§  Definition

The **DNS Firewall** helps you filter and control **DNS queries** originating from your VPC.
It integrates with **Route 53 Resolver** for internal DNS resolution.

---

### ğŸ”¹ Key Features

| Feature                  | Description                                           |
| ------------------------ | ----------------------------------------------------- |
| **Rule-based filtering** | Create allow, block, or alert actions for DNS queries |
| **Domain Lists**         | Use AWS Managed or Custom domain lists                |
| **Monitoring**           | Send logs to CloudWatch, S3, or Kinesis               |
| **Protection**           | Blocks malicious or phishing domains automatically    |

---

### ğŸ’¡ Use Cases

* **Security:** Block suspicious or unwanted domains
* **Compliance:** Prevent access to restricted domains
* **Control:** Centralize DNS management for your organization

---

## ğŸ§­ Tutorial: DNS Firewall Setup

### ğŸªœ Step 1 â€” Create Domain List

* Go to **VPC â†’ DNS Firewall â†’ Domain Lists â†’ Add Domain List**
* Add domains (e.g., `google.com`, `example.com`)

---

### ğŸªœ Step 2 â€” Create Rule Group

* Go to **VPC â†’ DNS Firewall â†’ Rule Groups â†’ Add Rule Group**

---

### ğŸªœ Step 3 â€” Add Rules

1. Open the Rule Group â†’ **Rules â†’ Add Rule**
2. Choose:

   * Domain List: **Custom** or **AWS Managed**
   * Action: **Allow / Block / Alert**
3. Save Rule

---

### ğŸªœ Step 4 â€” Associate Rule Group to VPC

1. Open your Rule Group â†’ **Associated VPCs â†’ Associate**
2. Select your target **VPC** â†’ Confirm

---

### ğŸ§ª Verification

On an EC2 instance terminal, run:

```bash
ping google.com
```

Result:

```
ping: google.com: Name or service not known
client_loop: send disconnect: Connection reset
```

âœ… DNS Firewall successfully **blocked the domain**.

---

# ğŸ“¦ AWS Managed Prefix Lists

### ğŸ§  Definition

**AWS Managed Prefix Lists** are pre-defined, automatically updated lists of **IP CIDR ranges** maintained by AWS.
They can be used in:

* **Route Tables**
* **Security Groups**
* **NACLs**

Instead of manually entering service IPs, you reference a **Prefix List ID**.

---

### ğŸ“‹ Key Points

| Feature            | Description                                     |
| ------------------ | ----------------------------------------------- |
| **Managed by AWS** | Includes IPs for S3, DynamoDB, CloudFront, etc. |
| **Auto-updated**   | AWS maintains and updates IP ranges             |
| **Reusable**       | Can be used across multiple VPCs and accounts   |
| **Secure**         | Simplifies access control to AWS services       |

---

### ğŸŒŸ Benefits

* No manual IP updates
* Consistent configuration across environments
* Simplified routing and security management

---

## ğŸ§­ Tutorial: AWS Managed Prefix Lists

### ğŸªœ Step 1 â€” Create a Prefix List

1. Navigate to **VPC â†’ AWS Managed Prefix Lists â†’ Create Prefix List**
2. Add:

   * Number of CIDR ranges
   * List all CIDR blocks you want to include

---

### ğŸªœ Step 2 â€” Attach Prefix List to Route Table

1. Open your **Route Table**
2. Add **Prefix List** as **Destination**
3. Scroll down to find your **Custom Prefix List**
4. Save configuration

âœ… The Prefix List is now active and can be reused for security rules or routing policies.

---

# ğŸ§  Summary

| Feature                  | Purpose                                       |
| ------------------------ | --------------------------------------------- |
| **Interface Endpoint**   | Private connection to AWS services using ENIs |
| **VPC Flow Logs**        | Monitor and audit VPC-level traffic           |
| **DNS Firewall**         | Filter and control DNS queries                |
| **Managed Prefix Lists** | Simplify routing and manage service IP ranges |

---
# â˜ï¸ Amazon EC2 â€” Elastic Compute Cloud

![AWS GIF](https://github.com/shyamdevk/AWS-Concepts-Labs/blob/images/ec2.gif)

> A complete and simplified guide to **Amazon EC2**, covering software installation, web hosting, AMIs, storage, snapshots, and instance types.

---

## ğŸ’¡ What is Amazon EC2?

**Amazon EC2 (Elastic Compute Cloud)** is a web service that provides **scalable, on-demand virtual servers** â€” called **instances** â€” in the AWS Cloud.

It allows users to deploy applications quickly, scale easily, and pay only for the compute resources they use.

---

## ğŸ§± Installing Software on EC2

### ğŸ”¹ Exercise: Installing Apache HTTP Server

**Apache** is one of the most popular web servers used to host and deliver web content.

- Default web directory:  
```

/var/www/html

````

---

### âš™ï¸ Step-by-Step Lab

1. **Launch an EC2 Instance** â†’ Connect to terminal.  
2. Access root privileges:
 ```bash
 sudo su
````

3. Install Apache:

   ```bash
   yum install httpd -y
   ```
4. Check Apache status:

   ```bash
   systemctl status httpd
   ```
   ![Screenshot](https://github.com/shyamdevk/AWS-Concepts-Labs/blob/images/dead.png)
5. If itâ€™s inactive (dead), start the service:

   ```bash
   systemctl start httpd
   ```
   ![Screenshot](https://github.com/shyamdevk/AWS-Concepts-Labs/blob/images/run.png)
6. Copy your **Public IP** and paste it into a browser to test.

   * HTTP â†’ Port **80**
   * HTTPS â†’ Port **443**
7. If not accessible:

   * Edit **Security Group** â†’ Add **HTTP (Port 80)** to **Inbound Rules**.
      ![Screenshot](https://github.com/shyamdevk/AWS-Concepts-Labs/blob/images/19.png)
8. To remove Apache:

   ```bash
   yum remove httpd -y
   ```

âœ… Apache is now installed and running on your EC2 instance!

---

## ğŸŒ Host a Custom Website on EC2

1. **Connect** to EC2
2. **Install Apache**
3. Navigate to the web directory:

   ```bash
   cd /var/www/html
   ```
4. Create your webpage:

   ```bash
   sudo vi index.html
   ```

   Add your HTML code â†’ Save (`:wq`)
5. Allow **Port 80** in your Security Group
6. Access:

   ```
   http://<EC2-Public-IP>
   ```
 ![Screenshot](https://github.com/shyamdevk/AWS-Concepts-Labs/blob/images/20.png)
 ![Screenshot](https://github.com/shyamdevk/AWS-Concepts-Labs/blob/images/21.png)
  
---

## ğŸ¨ Import a Custom CSS Template to EC2

1. Download template:

   ```bash
   wget <link-to-css-template>
   ```

   > **wget** downloads files from the internet via HTTP/HTTPS/FTP.

2. Extract ZIP file:

   ```bash
   unzip <file.zip>
   ```

3. Move contents to web directory:

   ```bash
   mv * /var/www/html
   ```

4. Open your EC2 **Public IP** in a browser â€” the CSS-based website should load.

---

# âš™ï¸ Using NGINX (Engine-X)

**Nginx** is a high-performance web server, reverse proxy, and load balancer designed for scalability and speed.

* Default directory:

  ```
  /usr/share/nginx/html
  ```

---

### ğŸªœ Install and Run Nginx

1. Install Nginx:

   ```bash
   yum install nginx -y
   ```
2. Start the service:

   ```bash
   sudo systemctl start nginx
   ```
3. Test by visiting your **EC2 Public IP** in a browser.

---
 ![Screenshot](https://github.com/shyamdevk/AWS-Concepts-Labs/blob/images/22.png)

### ğŸ§© Add a Custom Website to Nginx

1. Navigate to:

   ```bash
   cd /usr/share/nginx/html
   ```
2. Remove default files:

   ```bash
   sudo rm -rf *
   ```
3. Create new site:

   ```bash
   sudo vi index.html
   ```
4. Add HTML â†’ Save.

---

### ğŸ–¼ï¸ Add a Custom Template to Nginx

1. Download template:

   ```bash
   wget <link-to-template.zip>
   ```
2. Extract files:

   ```bash
   sudo unzip <filename.zip>
   ```
3. Remove ZIP:

   ```bash
   sudo rm -rf <filename.zip>
   ```
4. Run your EC2 **Public IP** to test website display.

---

# ğŸ§ Software Installation in Ubuntu EC2

### ğŸ§¾ Basic Details

* **Username:** `ubuntu`
* **Package Manager:** `apt`

---

### ğŸªœ Install Apache

```bash
sudo apt install apache2 -y
cd /var/www/html
```

Also install unzip:

```bash
sudo apt install unzip -y
```

---

### ğŸªœ Install Nginx

1. Update system:

   ```bash
   sudo apt update
   ```
2. Install:

   ```bash
   sudo apt install nginx -y
   ```
3. Web directory path:

   ```
   /var/www/html
   ```

---

# ğŸ” Proxy Concepts

### ğŸ”¹ Forward Proxy

* Acts **on behalf of clients**
* Filters and forwards client requests to the internet
* Used for **security**, **caching**, and **monitoring**

ğŸ‘‰ **Flow:**

```
Client â†’ Proxy â†’ Internet
```

---

### ğŸ”¹ Reverse Proxy

* Acts **on behalf of servers**
* Balances load, handles SSL, and hides backend structure

ğŸ‘‰ **Flow:**

```
Client â†’ Reverse Proxy â†’ Web Server
```

---

# ğŸªŸ Connect EC2 (Windows AMI)

* **Protocol:** RDP (Remote Desktop Protocol)
* **Authentication:** Uses Key Pair for Password Decryption

---

### ğŸªœ Steps

1. Select your **Windows Instance** â†’ **Connect**
2. Go to **RDP Client**
3. Upload **Key Pair**
4. Decrypt â†’ Copy generated password
5. Open the downloaded **RDP file**
6. Paste decrypted password to connect.

---

## ğŸŒ Install IIS Web Server (Windows)

1. Open **Server Manager**
2. Go to **Add Roles and Features**
3. Choose **Role: IIS Web Server**
4. Wait for installation
5. Open browser â†’ Enter EC2 **Public IP**
6. Default path:

   ```
   C:\inetpub\wwwroot
   ```
7. Use **Notepad** to create:

   ```
   index.html
   ```

---

# ğŸ§© AMI â€” Amazon Machine Image

### ğŸ“˜ Definition

A template to launch EC2 instances with:

* OS
* Applications
* Configurations
* EBS Volumes

---

### ğŸ§± Types of AMIs

1. **AWS-provided**
2. **Marketplace**
3. **Custom/Existing**

âœ… Used to launch **consistent environments** quickly.

---

## ğŸ”¹ 1. Existing AMI

* Created from an **existing EC2 instance**
* Used for:

  * Cloning setup
  * Scaling
  * Rollbacks

---

## ğŸ”¹ 2. Image Builder

AWS service to **automate AMI creation & updates**

**Features:**

* Automates patching & compliance
* Pipeline for testing and deployment

**Use Case:** Keep AMIs consistent across regions.

---

## ğŸ”¹ 3. EBS Backup & Snapshots

* **EBS Volume:** Persistent storage for EC2
* **Snapshot:** Point-in-time backup

  * Incremental
  * Stored in **S3**

**Use Cases:**

* Data restoration
* AMI creation
* Migration

---

## ğŸ”„ AMI Lifecycle
 ![Screenshot](https://github.com/shyamdevk/AWS-Concepts-Labs/blob/images/24.png)

1. Create EBS snapshot
2. Register as AMI
3. Launch new instances
4. Copy or share AMIs
5. Deregister when unused

> Command to auto-start Nginx:

```bash
systemctl enable nginx
```

---

## ğŸ§  Create Custom AMI

1. Select **Instance â†’ Actions â†’ Images and Templates â†’ Create Image**
2. Configure name & settings
3. Check progress:

   ```
   EC2 â†’ Images â†’ AMIs
   ```
4. Launch a new instance from the AMI
5. Share via:

   ```
   AMI â†’ Permissions â†’ Configure ID/OUs
   ```

---

# ğŸ’¾ Block Storage in AWS

Stores data in **fixed-size blocks**, offering **low-latency** performance for EC2.

---

## ğŸ“¦ 1. Instance Storage (Ephemeral)

* Temporary & attached to host
* High-speed
* Data lost on stop/terminate
* Use for cache/temp data

---

## ğŸ“¦ 2. Elastic Block Store (EBS)

* Persistent & network-attached
* Retains data after reboot
* Can attach/detach to multiple instances
* Supports **snapshots**

---

### âš™ï¸ Types of EBS Volumes

#### ğŸ§  SSD (Solid State Drives)

| Type        | Use Case                        |
| ----------- | ------------------------------- |
| **gp3/gp2** | General workloads, boot volumes |
| **io2/io1** | High IOPS, mission-critical DBs |

#### ğŸ’½ HDD (Hard Disk Drives)

| Type    | Use Case               |
| ------- | ---------------------- |
| **st1** | Big data, streaming    |
| **sc1** | Cold storage, low-cost |

---

# ğŸ§ª Lab: Attach & Mount a New EBS Volume

### ğŸªœ Steps

1. EC2 â†’ **Elastic Block Store â†’ Volumes**
2. Create & configure volume
3. **Attach** to instance â†’ Same region
4. Connect via terminal

Check devices:

```bash
lsblk
```

---

### ğŸ§± Mounting Process

1. Check filesystem:

   ```bash
   sudo file -s /dev/xvdb
   ```
2. Format disk:

   ```bash
   sudo mkfs -t ext4 /dev/xvdb
   ```
3. Mount volume:

   ```bash
   sudo mount /dev/xvdb /mnt/mountpoint
   ```
4. Verify mount:

   ```bash
   lsblk
   ```

---

### ğŸ—‚ï¸ Permanent Mount

1. Remount after reboot:

   ```bash
   sudo mount /dev/xvdb /mnt/mountpoint
   ```
2. Edit `/etc/fstab`:

   ```
   /dev/xvdb /mnt/mountpoint ext4 defaults,nofail 0 2
   ```

âœ… Mounts automatically on startup.

---

# ğŸ“¸ EBS Snapshots

### ğŸ”¹ Definition

A **point-in-time backup** of an EBS volume â€” used for restore or replication.

**Features:**

* Incremental
* Stored in **S3**
* Cross-region support
* Automated backups via Lifecycle Policies

---

### ğŸ§­ Snapshot Tutorial

1. Select **Volume â†’ Actions â†’ Create Snapshot**
2. Check **EC2 â†’ Snapshots**
3. Create **Volume from Snapshot**
4. Mount it using:

   ```bash
   sudo mount -t xfs -o nouuid /dev/xvdb1 /mnt/mount
   ```
 ![Screenshot](https://github.com/shyamdevk/AWS-Concepts-Labs/blob/images/23.png)
> **UUID:** Universally Unique Identifier for disks/filesystems

---

# âš™ï¸ Amazon EC2 Instance Types

| Type                       | Example | Description                   |
| -------------------------- | ------- | ----------------------------- |
| **General Purpose**        | t3, m5  | Balanced CPU & memory         |
| **Compute Optimized**      | c5      | High CPU, compute-heavy tasks |
| **Memory Optimized**       | r5      | Large memory for databases    |
| **Storage Optimized**      | i3, d2  | High I/O performance          |
| **Accelerated Computing**  | p3, g4  | GPU-powered for AI/ML         |
| **High Performance (HPC)** | hpc6id  | Supercomputing workloads      |

---

## ğŸ§© EC2 Instance Naming Convention

Format:

```
<family><generation><features>.<size>
```

### Examples:

| Instance         | Meaning                              |
| ---------------- | ------------------------------------ |
| **t2.micro**     | General Purpose, 2nd Gen, small size |
| **c5.large**     | Compute Optimized, 5th Gen, mid-size |
| **r6g.xlarge**   | Memory Optimized, 6th Gen (Graviton) |
| **i3.2xlarge**   | Storage Optimized, 3rd Gen           |
| **g4dn.4xlarge** | GPU-based, 4th Gen with NVIDIA GPU   |

---
# â˜ï¸ Amazon EC2 â€” Advanced Concepts

> A complete, practical guide to **Amazon EC2 advanced configurations**, covering purchasing models, SSH key management, automation, networking, and performance optimization.

---

## ğŸ’¸ Amazon EC2 Purchasing Options

| Option | Description | Best For |
|--------|--------------|----------|
| **1ï¸âƒ£ On-Demand Instances** | Pay only for what you use. No long-term commitment. | Short-term or unpredictable workloads. |
| **2ï¸âƒ£ Reserved Instances (RI)** | Buy for 1 or 3 years at a discounted rate. | Long-term, steady workloads. |
| **3ï¸âƒ£ Spot Instances** | Use unused EC2 capacity (up to 90% cheaper). Can be interrupted anytime. | Batch jobs, flexible & fault-tolerant tasks. |
| **4ï¸âƒ£ Savings Plans** | Commit to a fixed $/hour usage for 1 or 3 years. Works across EC2, Fargate, Lambda. | Long-term workloads with flexibility. |
| **5ï¸âƒ£ Dedicated Hosts** | Entire physical server dedicated to one customer. | Compliance, licensing, and isolation. |
| **6ï¸âƒ£ Dedicated Instances** | Runs on isolated hardware (managed by AWS). | When isolation is needed without full control. |
| **7ï¸âƒ£ Capacity Reservations** | Reserve capacity in a specific AZ. No long-term contract. | Ensures guaranteed instance availability. |

---

## ğŸ” Key Pair & Recovery

A **Key Pair** in AWS consists of a **public key** and **private key** for secure SSH login.

- **Private Key:** Owned by the user.  
- **Public Key:** Stored inside the instance at  
```

/home/ec2-user/.ssh/authorized_keys

````

---

### ğŸ§­ Exercise: Recover EC2 When Private Key is Lost (Using a Dummy Server)

1. **Detach** volume from the main instance.  
2. **Attach** it to a **dummy instance**.
3. **Mount** main volume:
 ```bash
 sudo mount -t xfs -o nouuid /dev/xvdb1 /mnt/mount
````

4. **Copy authorized_keys:**

   ```bash
   sudo mv authorized_keys /mnt/mount/home/ec2-user/.ssh/authorized_keys
   ```
5. **Detach** main volume â†’ **Reattach** to the main instance (ensure device name = root).
6. Start instance â†’ Connect using **dummy serverâ€™s key-pair**.

âœ… The main instance now accepts the dummy serverâ€™s key-pair for SSH access.

---

### ğŸ”‘ Alternate Method: Generate a New RSA Key Pair

1. Create key pair:

   ```bash
   ssh-keygen -t rsa
   ```
2. Generated files inside `.ssh`:

   * `id_rsa` â†’ Private Key
   * `id_rsa.pub` â†’ Public Key
3. Move public key to `authorized_keys`:

   ```bash
   mv test.pub authorized_keys
   ```
4. Convert key to RSA (PEM) format:

   ```bash
   ssh-keygen -p -m PEM -f test
   ```
5. Copy public key â†’ Save to text file â†’ Use it for SSH authentication.

---

# ğŸš Linux Shell Scripting

### ğŸ§  Shell

A **shell** is a command-line interpreter that interacts with the OS.
**Examples:** Bash, Zsh, Sh, Ksh.

### âš™ï¸ Shell Scripting

Writing a series of shell commands in a `.sh` file to automate repetitive tasks.

---

### ğŸ§ª Exercise: Create a Script to Install Apache & Host a Website

1. Create file:

   ```bash
   vi web.sh
   ```
2. Add:

   ```bash
   #!/bin/bash
   yum update -y
   yum install httpd -y
   systemctl start httpd
   systemctl enable httpd
   echo "<h1>Hi From Website</h1>" >> /var/www/html/index.html
   ```
3. Give execute permission:

   ```bash
   chmod 700 web.sh
   ```
4. Run script:

   ```bash
   ./web.sh
   ```

âœ… Automatically installs Apache and hosts a simple web page.

---

# âš¡ User Data in EC2

### ğŸ§  Definition

**User Data** = A script or command that runs **automatically** when an EC2 instance first boots.

---

### ğŸªœ Steps

1. During EC2 creation â†’ go to **Advanced Details â†’ User Data**
2. Add:

   ```bash
   #!/bin/bash
   yum update -y
   yum install httpd -y
   systemctl start httpd
   systemctl enable httpd
   echo "<h1>Hi From Website</h1>" >> /var/www/html/index.html
   ```
3. After launch, Apache installs and runs automatically.

---

### ğŸ§¹ Updating User Data

* Stop the instance
* Go to **Actions â†’ Edit User Data**
* To reload new data:

  ```bash
  sudo rm -rf /var/lib/cloud/*
  ```

  Then execute:

  ```bash
  sudo cloud-init init
  sudo cloud-init modules --mode=config
  sudo cloud-init modules --mode=final
  ```

âœ… Clears cache and forces re-run of User Data.

---

# ğŸŒ Elastic Network Interface (ENI)

### ğŸ§  Definition

An **ENI** is a virtual network card attached to an EC2 instance.

Each ENI includes:

* Private IP (mandatory)
* Optional Public/Elastic IP
* MAC address
* Security Groups

---

### ğŸ§­ Exercise: Attach an Additional ENI

1. **Instance â†’ Networking â†’ Network Interfaces**
2. Create new ENI â†’ select **subnet** and **security group**
3. Actions â†’ **Attach** to instance
4. Allocate **Elastic IP â†’ Associate â†’ Resource Type: Network Interface**
5. Confirm instance now has:

   * 2 Private IPs
   * 1 Public & Elastic IP

> ğŸ“ Note: New ENIs donâ€™t have a public IP unless manually assigned.

---

### ğŸ¯ Assign Custom IP

During instance launch:

> Go to **Network Settings â†’ Advanced Network Configuration â†’ Custom Private IP**

---

# ğŸŒ Virtual Hosting

### ğŸ§  Definition

Host **multiple websites** on a **single EC2 instance** (or single IP address).

Two types:

1. **Name-Based Virtual Hosting** â€” by domain name
2. **IP-Based Virtual Hosting** â€” by IP address

---

### ğŸ§­ Exercise: Host 2 Websites Using 2 ENIs

1. Inside `/var/www/html`, create two directories:

   ```
   web1
   web2
   ```
2. Add separate `index.html` files in each.
3. Edit config file:

   ```bash
   vi /etc/httpd/conf/httpd.conf
   ```

   Add:

   ```html
   <VirtualHost Private-IP1>
       DocumentRoot "/var/www/html/web1"
   </VirtualHost>

   <VirtualHost Private-IP2>
       DocumentRoot "/var/www/html/web2"
   </VirtualHost>
   ```
    ![Screenshot](https://github.com/shyamdevk/AWS-Concepts-Labs/blob/images/25.png)
4. Restart Apache:

   ```bash
   sudo systemctl restart httpd
   ```

âœ… Access both web pages using the respective **Public or Elastic IPs**.

---

# ğŸ’» PuTTY Software

**PuTTY** is a free SSH client for Windows that connects to remote systems via SSH, Telnet, or Rlogin.

### âš™ï¸ Setup Guide

1. Download **PuTTY** and **PuTTYgen** from the official site.
2. Convert `.pem` to `.ppk` using PuTTYgen.
3. In PuTTY:

   * **Session:** Enter Public IP
   * **SSH â†’ Auth â†’ Credentials:** Browse `.ppk` file
   * Click **Open**

âœ… Youâ€™re connected to EC2 from Windows!

---

# ğŸ”’ Session Manager (AWS Systems Manager)

**Session Manager** lets you connect to EC2 **without SSH, key pairs, or open ports**.

---

### âš™ï¸ Setup Steps

1. Ensure the **SSM Agent** is installed (preinstalled in most AMIs).
2. Create an IAM Role with:

   ```
   AmazonSSMManagedInstanceCore
   ```
3. Attach IAM role:

   ```
   Actions â†’ Security â†’ Modify IAM Role
   ```
4. Connect:

   ```
   Instance â†’ Connect â†’ Session Manager â†’ Start Session
   ```

âœ… Secure browser-based shell without SSH keys or open ports.

---

# ğŸ–¥ï¸ EC2 Serial Console

### ğŸ§  Definition

Direct console access to EC2, similar to a **physical server monitor**.
Works **without the internet** (for troubleshooting system-level issues).

> Supported only on **Nitro-based instances**.

---

### âš™ï¸ Setup

1. Enable:

   ```
   EC2 â†’ Settings â†’ EC2 Serial Console â†’ Allow
   ```
2. Stop instance â†’ Restart on Nitro Hypervisor
3. Connect:

   ```
   Instance â†’ Connect â†’ EC2 Serial Console
   ```
4. Log in using **local user credentials** (create via CLI if not set).

---

# âš™ï¸ Burstable vs Fixed Performance Instances

### ğŸ’¡ Classification Based on CPU Performance

#### ğŸ”¹ Burstable Performance Instances

* Provide **baseline CPU** performance with **credit-based bursting**.
* Earn CPU credits when idle.
* Example: `t2`, `t3`, `t3a`, `t4g`

Use for cost efficiency and variable workloads.

---

#### ğŸ”¹ Fixed Performance Instances

* Offer **consistent, dedicated CPU** performance.
* No CPU credits or bursts.
* Example: `m5`, `m6i`, `c5`, `r5`, `r6i`

Use for predictable workloads needing steady performance.

---

# âš–ï¸ Load Balancer in AWS

### ğŸ§  Definition

A **Load Balancer (ELB)** distributes incoming traffic across multiple targets (EC2s, containers, IPs).

---

### ğŸ”¹ How It Works

**Flow:**

```
User â†’ Listener â†’ Routing Rule â†’ Target Group â†’ EC2
```

**Components:**

* **Listener:** Detects requests (HTTP/HTTPS)
* **Routing:** Decides target group
* **Security Group:** Firewall for ELB
* **Health Checks:** Only routes to healthy targets

---

### ğŸ¯ Purpose

* Improves availability & fault tolerance
* Increases scalability
* Routes traffic only to healthy instances

---

## ğŸ§© Types of Load Balancers

| Type                                   | Layer     | Use Case                                        |
| -------------------------------------- | --------- | ----------------------------------------------- |
| **1. Application Load Balancer (ALB)** | Layer 7   | Web apps, microservices (HTTP/HTTPS)            |
| **2. Network Load Balancer (NLB)**     | Layer 4   | TCP/UDP/TLS, real-time or low-latency apps      |
| **3. Gateway Load Balancer (GLB)**     | Layer 3   | Integrates with third-party firewalls & IDS/IPS |
| **4. Classic Load Balancer (CLB)**     | Layer 4/7 | Legacy load balancing (limited features)        |

---

# âš–ï¸ Load Balancer (Elastic Load Balancing - ELB)

A **Load Balancer (LB)** automatically distributes incoming network traffic across multiple EC2 instances to ensure high availability and reliability.

---

## ğŸ’¡ LAB â€” Create Load Balancer in AWS

**Goal:** Create an **Application Load Balancer (ALB)** to manage traffic between multiple web servers.

### ğŸªœ Steps:

1. **Launch 2 EC2 Instances**
   - Deploy simple web pages on both (e.g., Apache with different content).

2. **Create a Target Group**
   - Go to: `EC2 â†’ Target Groups â†’ Create`
   - Select **Instances** as the target type.
   - Configure settings â†’ Register both EC2 instances.
   - Create the **Target Group**.

3. **Create Load Balancer**
   - Navigate to: `EC2 â†’ Load Balancers â†’ Create Load Balancer`
   - Choose **Application Load Balancer**
   - Select **Internet-facing scheme**
   - Choose **subnets** and **security group**
   - Under **Listeners & Routing**, select your **Target Group**
   - Click **Create**

4. **Test Your Load Balancer**
   - Copy the **DNS name** of your ALB
   - Paste it in the browser:
     - It will load **one website**, and when refreshed, switch to the **other instance**.

âœ… Ensure **HTTP (Port 80)** is allowed in the Load Balancerâ€™s security group.

---

# âš™ï¸ Auto Scaling in AWS

### ğŸ§  Definition
**Auto Scaling** automatically adjusts the number of EC2 instances according to demand, ensuring consistent performance and cost optimization.

---

## ğŸ”¹ Types of Scaling

### 1ï¸âƒ£ Horizontal Scaling (Scale Out/In)
- Adds or removes **instances** based on demand.  
  Example:
  - Traffic â†‘ â†’ Add EC2s  
  - Traffic â†“ â†’ Remove EC2s

### 2ï¸âƒ£ Vertical Scaling (Scale Up/Down)
- Changes **instance size** to increase/decrease performance.  
  Example:
  - Upgrade `t2.micro â†’ t2.large`

---

# ğŸ§© Auto Scaling Group (ASG)

An **ASG** manages a group of EC2 instances collectively. It automatically maintains the desired instance count.

### âš™ï¸ Capacity Settings

| Setting | Description |
|----------|--------------|
| **Minimum Capacity** | Minimum number of instances always running |
| **Maximum Capacity** | Maximum limit of instances allowed |
| **Desired Capacity** | Normal (target) number of running instances |

---

# ğŸ§± Launch Template (LT)

A **Launch Template** defines configuration details for instances launched by Auto Scaling.

### ğŸ“¦ Launch Template Includes:

- AMI (Amazon Machine Image)
- Instance Type (e.g., `t2.micro`)
- Key Pair (SSH access)
- Security Groups
- User Data (startup scripts)
- EBS Storage configuration
- IAM Role (permissions)

---

## ğŸ’¡ LAB 1 â€” Create an Auto Scaling Group

### ğŸªœ Steps:

1. **Create a Launch Template**
   - `EC2 â†’ Launch Templates â†’ Create`
   - Add instance configuration (AMI, SG, Key Pair, etc.)

2. **Create Auto Scaling Group**
   - `EC2 â†’ Auto Scaling Groups â†’ Create`
   - Select Launch Template
   - Configure network/subnets
   - Define **Min, Max, Desired** capacity
   - Add notifications or tags (optional)
   - Create group

3. **Observe Activity**
   - View **Activity tab** to see scaling actions
   - If one instance stops, a new one is launched automatically.

4. **Manual Scaling**
   - `ASG â†’ Edit â†’ Capacity Overview`
   - Adjust instance count manually.

---

## ğŸ’¡ LAB 1.1 â€” Integrate Load Balancer with Auto Scaling

1. Open ASG â†’ **Integration tab**
2. Add or create a **Load Balancer**
3. Choose **Internet-Facing** scheme
4. Create/attach a **Target Group**
5. Allow **Port 80** (HTTP) in the security group.

âœ… ASG now routes traffic through the Load Balancer and maintains availability.

---

# ğŸ§¾ Launch Configuration vs Launch Template

| Feature | Launch Configuration | Launch Template |
|----------|----------------------|-----------------|
| Versioning | âŒ Not supported | âœ… Supported |
| Reusability | Single-use | Multi-version |
| Network Interfaces | Limited | Full control |
| Security Group Updates | Manual recreation | Seamless version update |
| User Data | Basic | Advanced (scripts, parameters) |

---

## ğŸ§ª Exercise â€” Modify Launch Template with Load Balancer

1. Create **Launch Template**
2. Launch **Load Balancer** using the template
3. Edit template:
   - `Actions â†’ Modify â†’ Create New Version`
4. Update version in **Load Balancer**
5. Relaunch instances â†’ Apply new version settings.

---

# ğŸ“Š Auto Scaling Policies

**Scaling Policies** define *when and how* ASG adds/removes EC2 instances.

---

## ğŸ”¸ 1. Dynamic Scaling Policy
- Based on **CloudWatch metrics** (e.g., CPU > 80%)
- Automatically adds/removes instances
![Screenshot](https://github.com/shyamdevk/AWS-Concepts-Labs/blob/images/27.png)
---

## ğŸ”¸ 2. Predictive Scaling Policy
- Uses **machine learning** to forecast traffic
- Scales ahead of time
- Example: Adds instances every morning before peak hours

---

## ğŸ”¸ 3. Scheduled Scaling Policy
- You manually set fixed times for scaling
- Example: Add 5 instances at 9 AM every weekday
 ![Screenshot](https://github.com/shyamdevk/AWS-Concepts-Labs/blob/images/28.png)
---

### âœ… Example Flow
```

CloudWatch monitors CPU â†’ Policy triggers at 80% â†’
ASG adds new instances via Launch Template â†’
When CPU drops, extra instances are terminated

````

ğŸ§  **Note:** Lab continues with CloudWatch integration.

---

# ğŸ” Amazon CloudWatch (Monitoring & Alarms)

![AWS GIF](https://github.com/shyamdevk/AWS-Concepts-Labs/blob/images/cloudwatch.gif)

### ğŸ§  Definition
**CloudWatch** monitors AWS resources and applications in real-time â€” providing metrics, logs, dashboards, and automated actions.

---

## ğŸ¯ Key Features

| Feature | Description |
|----------|--------------|
| **Metrics** | Data points measuring performance (CPU, Network, Disk) |
| **Alarms** | Trigger actions when thresholds are crossed |
| **Logs** | Store application/system logs |
| **Dashboards** | Visual display of metrics |
| **Events / Rules** | Automated responses to resource changes |

---

## ğŸ’¡ How CloudWatch Works

1. Collects metrics from AWS services (EC2, RDS, Lambda)
2. Creates alarms for thresholds
3. Alarm can:
   - Send SNS alert  
   - Trigger Auto Scaling  
   - Invoke Lambda functions  

---

## ğŸ§ª Example Scenario
CloudWatch monitors CPU utilization:
- If CPU > 80% â†’ Alarm activates
- ASG adds a new EC2 instance

---

# ğŸ§­ LAB â€” Monitor EC2 with CloudWatch

### ğŸªœ Steps:

1. Launch EC2 â†’ Enable **Detailed Monitoring**  
2. Open CloudWatch â†’ Metrics â†’ EC2 â†’ Select your Instance ID  
3. Choose a metric (e.g., **CPUUtilization**)  
4. Generate stress:
   ```bash
   sudo yum install stress -y
   stress --cpu 20 --timeout 300

5. Observe CloudWatch â†’ CPU usage spikes in few minutes.

âœ… Verified CloudWatch metric collection.

---

# âš™ï¸ LAB â€” Target Tracking Policy

**Goal:** Trigger an alarm automatically and scale ASG based on CPU.

### ğŸªœ Steps:

1. Create Launch Template â†’ Enable **CloudWatch Monitoring**
2. Launch ASG â†’ Configure **Health Check Period**
3. Go to ASG â†’ **Automatic Scaling Policy â†’ Create Dynamic Policy**
 ![Screenshot](https://github.com/shyamdevk/AWS-Concepts-Labs/blob/images/29.png)
4. A CloudWatch **Alarm** will be automatically created.
 ![Screenshot](https://github.com/shyamdevk/AWS-Concepts-Labs/blob/images/30.png)
5. From EC2 CLI, generate load:

   ```bash
   stress --cpu 60 --timeout 300
   ```
6. When CPU > Target (e.g., 50%), the alarm triggers, and a new EC2 instance is added.

âœ… Verified automatic scaling response.

---

# ğŸš¨ Amazon CloudWatch Alarm

### ğŸ§  What is an Alarm?

A **CloudWatch Alarm** monitors a specific metric and triggers actions when the threshold is breached.

---

### ğŸ“Š Alarm States

| State                 | Meaning                   |
| --------------------- | ------------------------- |
| **OK**                | Everything is normal      |
| **ALARM**             | Metric crossed threshold  |
| **INSUFFICIENT DATA** | Not enough data collected |

---

### âš™ï¸ Alarm Conditions

| Parameter | Example         |
| --------- | --------------- |
| Metric    | CPUUtilization  |
| Statistic | Average         |
| Operator  | >, <, â‰¥, â‰¤      |
| Threshold | 80              |
| Period    | Every 5 minutes |

---

## ğŸ§­ LAB â€” Setup Alarm for EC2 Metric

1. Launch instance â†’ Enable **Detailed Monitoring**
2. CloudWatch â†’ All Metrics â†’ EC2 â†’ Per-Instance metrics
3. Select your instance â†’ Metric (CPUUtilization)
 ![Screenshot](https://github.com/shyamdevk/AWS-Concepts-Labs/blob/images/31.png)
4. Create Alarm â†’ Configure threshold â†’ Skip action
5. Add details â†’ Create Alarm
6. Generate stress:

   ```bash
   stress --cpu 20 --timeout 300
   ```

âœ… Alarm triggers when CPU crosses the defined threshold.

---

# âš¡ Simple Scaling Policy

**Simple Scaling** = One CloudWatch alarm triggers one scaling action.

---

### ğŸ§© Example Flow

1. Alarm: CPU > 80% â†’ Add 1 instance
2. Cooldown period (stabilize)
3. Alarm: CPU < 40% â†’ Remove 1 instance

---

### ğŸ§­ LAB â€” Simple Scaling

1. Create Launch Template (enable monitoring)
2. Launch ASG
3. Create CloudWatch Alarm
4. Create Policy:

   * `ASG â†’ Edit â†’ Dynamic Scaling Policy`
   * Link alarm to scale-out action
 ![Screenshot](https://github.com/shyamdevk/AWS-Concepts-Labs/blob/images/32.png)
5. Generate stress to trigger alarm:

   ```bash
   stress --cpu 60 --timeout 300
   ```

âœ… Instance added automatically after alarm triggers.

---

# âš™ï¸ Step Scaling Policy

**Step Scaling** = Adds or removes instances **gradually**, depending on how much the metric crosses the threshold.

---

### ğŸ§  Example

| CPU Utilization | Action            |
| --------------- | ----------------- |
| >60%            | Add 1 instance    |
| >80%            | Add 2 instances   |
| <40%            | Remove 1 instance |

---

### ğŸ§­ LAB â€” Step Scaling Policy

1. Launch Template â†’ Enable CloudWatch Monitoring
2. Launch ASG
3. Create Alarm â†’ Add **SNS Notification Topic (Email)**

   * Subscribe to the topic (check spam folder)
4. Create Dynamic Policy:
 ![Screenshot](https://github.com/shyamdevk/AWS-Concepts-Labs/blob/images/33.png)
   * Step 1 â†’ Add instance if CPU >50%
   * Step 2 â†’ Add another instance if CPU >60%

âœ… ASG scales stepwise according to CPU load.

---

# ğŸŒ©ï¸ Summary

| Feature                | Purpose                                       |
| ---------------------- | --------------------------------------------- |
| **Load Balancer**      | Distributes traffic across EC2 instances      |
| **Auto Scaling Group** | Automatically manages instance count          |
| **Launch Template**    | Predefined EC2 configuration for ASG          |
| **Scaling Policies**   | Define when/how scaling occurs                |
| **CloudWatch**         | Monitors metrics and triggers scaling actions |

---
# â˜ï¸ Amazon CloudWatch â€” Advanced Concepts  

> A complete continuation guide covering **CloudWatch Alarms, Dashboards, and Grafana Integration** for advanced AWS monitoring and visualization.

---

# ğŸ§  What is Amazon CloudWatch?

**Amazon CloudWatch** is a real-time monitoring and observability service that tracks metrics, logs, and events from AWS resources and applications.

It helps you:
- Monitor performance (CPU, Memory, Disk, Network)
- Create alarms and automated actions
- Visualize metrics through dashboards
- Integrate with external monitoring tools like **Grafana**

---

# ğŸš¨ CloudWatch Alarms

### 1ï¸âƒ£ What is a CloudWatch Alarm?

A **CloudWatch Alarm** continuously monitors metrics and **triggers actions** when a specified threshold is crossed.

**Example:**
> Trigger an alarm when CPU Utilization > 80% for 5 minutes.

---

## ğŸ“Œ Types of CloudWatch Alarms

### ğŸ”¹ 1. Metric Alarm
- Monitors a **single metric** (e.g., `CPUUtilization`, `DiskReadOps`, `NetworkIn`)
- Triggers when metric value exceeds or drops below a defined threshold.
- Most commonly used alarm type.

**Example:**
```text
Alarm: CPUUtilization > 80%
Action: Send notification or scale EC2
````

---

### ğŸ”¹ 2. Composite Alarm

* Combines multiple **metric alarms** using logical operators (**AND / OR**)
* Useful for reducing **false positives**

**Example:**

> Alarm triggers only if:
> `CPU > 80% AND Memory > 75%`

âœ… Great for multi-metric monitoring (e.g., EC2 + RDS health checks).

---

### ğŸ”¹ 3. Anomaly Detection Alarm

* Uses **Machine Learning** to automatically detect normal metric patterns.
* Alarm triggers when the metric value moves outside the predicted range.
* Ideal for **unpredictable or fluctuating workloads**.

**Example:**

> Detect unusual network spikes or CPU anomalies automatically.

---

# ğŸ“Š CloudWatch Dashboard

### ğŸ§  Definition

A **CloudWatch Dashboard** is a customizable visual panel to view multiple metrics and alarms in one place.

You can add:

* ğŸ“ˆ CPU Utilization graphs
* ğŸŒ Network Traffic trends
* ğŸ’¾ Disk I/O metrics
* âš ï¸ Alarm statuses
* ğŸ§¾ Log insights
* ğŸ’¡ Custom Metrics

---

### ğŸ’¡ Why Use a Dashboard?

| Benefit                  | Description                                           |
| ------------------------ | ----------------------------------------------------- |
| **Centralized View**     | Monitor all key AWS metrics in one console            |
| **Real-Time Monitoring** | Track EC2, RDS, and ELB performance instantly         |
| **Troubleshooting**      | Identify issues faster using visual data              |
| **Custom Metrics**       | Display app-specific data or CloudWatch Logs insights |

---

# ğŸ§­ LAB â€” Create Custom Dashboard for an Instance

### ğŸªœ Steps:

1. **Launch an EC2 Instance**

   * Enable **Detailed Monitoring** for CloudWatch.

2. **Navigate to CloudWatch:**

   * Open: `CloudWatch â†’ Dashboards â†’ Create Dashboard`

3. **Customize Your Dashboard:**

   * Choose visualization type (Line, Stacked, Number, Text)
   * Select Metrics â†’ EC2 â†’ Per-Instance Metrics
   * Choose metrics such as:

     * CPUUtilization
     * NetworkIn / NetworkOut
     * DiskReadOps / DiskWriteOps

4. Add widgets as needed â†’ Save Dashboard.

âœ… You now have a real-time custom dashboard for your instance!

---

# ğŸ“‰ LAB â€” Visualize CloudWatch Data Using Grafana

**Goal:** Use Grafana to display CloudWatch metrics visually using real-time dashboards.

---

### âš™ï¸ Requirements

* **2 EC2 Instances**

  * One for **Grafana Server**
  * One for **Monitoring (Target Instance)**

---

### ğŸªœ Steps:

#### Step 1 â€” Install Grafana

1. SSH into the **Grafana Instance**
2. Install Grafana (follow official instructions):

   ```bash
   sudo yum install grafana -y
   sudo systemctl start grafana-server
   sudo systemctl enable grafana-server
   ```
3. Access Grafana in your browser:

   ```
   http://<Grafana-Instance-Public-IP>:3000
   ```

   * Default credentials:

     ```
     Username: admin
     Password: admin
     ```

---

#### Step 2 â€” Connect Grafana to CloudWatch

1. Go to:
   `Grafana â†’ Connections â†’ Data Sources â†’ Add Data Source â†’ Amazon CloudWatch`

2. Under **Authentication Provider**, select:

   ```
   Access & Secret Key
   ```

3. Provide:

   * **Access Key ID**
   * **Secret Access Key**
     (You can get these from the **Root User** or **IAM User**)

4. Click **Save & Test**

---

#### Step 3 â€” IAM Role & Permissions

* Ensure your **Grafana Instance** has an **IAM Role** attached with:

  ```
  CloudWatchFullAccess
  ```
* Attach via:

  ```
  EC2 â†’ Actions â†’ Security â†’ Modify IAM Role
  ```

âœ… Grafana can now access CloudWatch metrics.

---

#### Step 4 â€” Create Grafana Dashboard

1. In Grafana, go to:

   ```
   Dashboards â†’ Create New Dashboard â†’ Add Visualization
   ```
2. Choose **Data Source: CloudWatch**
3. Add metrics such as:

   * CPUUtilization
   * NetworkIn / NetworkOut
   * Disk I/O
   * Latency / Requests for ALB
4. Customize visualization types (Graphs, Gauges, Heatmaps, etc.)

âœ… Your Grafana Dashboard now displays live CloudWatch metrics!

---

# ğŸ’¡ Benefits of Using Grafana with CloudWatch

| Feature                  | Description                                       |
| ------------------------ | ------------------------------------------------- |
| **Rich Visualizations**  | Beautiful charts and dashboards                   |
| **Multi-Source Support** | Combine AWS CloudWatch with other data sources    |
| **Alerting System**      | Create advanced alerts beyond CloudWatch defaults |
| **Team Collaboration**   | Share dashboards easily across teams              |
| **Real-Time Analytics**  | Live data from AWS services                       |

---

# ğŸ“¦ Summary

| Concept                     | Description                                         |
| --------------------------- | --------------------------------------------------- |
| **Metric Alarm**            | Monitors single metric for threshold breaches       |
| **Composite Alarm**         | Combines multiple alarms using AND/OR logic         |
| **Anomaly Detection Alarm** | Detects unusual behavior using ML                   |
| **CloudWatch Dashboard**    | Centralized visual display of all metrics           |
| **Grafana Integration**     | External visualization tool connected to CloudWatch |

---

# ğŸ“¢ Amazon SNS (Simple Notification Service) â€“ Complete Guide & Lab Setup

![AWS GIF](https://github.com/shyamdevk/AWS-Concepts-Labs/blob/images/sns.gif)

Amazon SNS (Simple Notification Service) is a **fully managed messaging service** that enables applications to send notifications/messages to subscribers instantly and reliably.

---

## ğŸš€ Why Use Amazon SNS?

SNS is used to:

* âš¡ Send real-time alerts/notifications
* ğŸ”„ Fan-out messages to multiple systems
* ğŸ”— Trigger workflows across AWS services
* ğŸ“© Notify end-users via Email, SMS, Mobile Push

---

## ğŸ”‘ Key Concepts in SNS

### **1. ğŸ§µ Topic**

A **Topic** is a communication channel where publishers send messages and subscribers receive them.

SNS supports two types of topics:

#### **1ï¸âƒ£ Standard Topic**

* High throughput
* Best-effort ordering
* Possible duplicates
* Fastest delivery

#### **2ï¸âƒ£ FIFO Topic**

* **F**irst **I**n **F**irst **O**ut ordering
* No duplicates
* Limited throughput
* Used when **message order matters**

---

### **2. ğŸ“¨ Publisher**

* The **sender** of the message
* Can be an application or AWS service

  * e.g., CloudWatch, Lambda, EC2

---

### **3. ğŸ‘¤ Subscriber**

Receives messages from the topic.
Common subscriber types:

* ğŸ“§ Email
* ğŸ“± SMS
* ğŸŒ HTTP/HTTPS endpoint
* ğŸ”— Amazon SQS
* ğŸ§  AWS Lambda

---

### **4. ğŸ’¬ Message**

The actual notification/alert sent to subscribers.

---

## ğŸ”„ SNS Workflow (Simple Flow)

```
Publisher â†’ SNS Topic â†’ Subscribers
```

**Steps:**

1. Create an SNS Topic
2. Add Subscriber(s)
3. Publisher sends a message
4. SNS delivers to all subscribers

---

## ğŸ’¡ Common Use Cases

| Use Case                    | Example                   |
| --------------------------- | ------------------------- |
| Cloud alerts                | CloudWatch â†’ SNS â†’ Email  |
| Fan-out architecture        | SNS â†’ multiple SQS queues |
| Serverless triggers         | SNS â†’ Lambda              |
| User notifications          | Email/SMS alerts          |
| Microservices communication | Event-driven apps         |

---

## ğŸ“¬ Types of SNS Messaging

### **1. Application-to-Application (A2A) Messaging**

Apps talk to apps using SNS.
 ![Screenshot](https://github.com/shyamdevk/AWS-Concepts-Labs/blob/images/app.png)

ğŸ“Œ Examples:

* SNS Topic â†’ Lambda
* SNS â†’ SQS
* CloudWatch â†’ SNS â†’ EC2/Lambda
* Microservice Event Distribution

SNS helps to **fan-out** messages to multiple backend systems.

---

### **2. Application-to-Person (A2P) Messaging**

Application sends messages directly to users.
 ![Screenshot](https://github.com/shyamdevk/AWS-Concepts-Labs/blob/images/app2.png)
ğŸ“Œ Examples:

* OTP
* Login Alert
* Bank Notifications
* Email Alerts

SNS supports:

* SMS
* Email
* Mobile push notifications

---

# ğŸ§ª LAB: Send Notifications from S3 to User via SNS

Goal:
**Create an SNS Topic that sends a message to the user whenever an S3 Event occurs (like object upload/delete).**

---

## ğŸ§· Step-by-Step Instructions

### **1ï¸âƒ£ Create an SNS Topic**

* Go to **SNS â†’ Topics â†’ Create Topic**
* Type: **Standard**
* Enter a name
* Click **Create Topic**

---

### **2ï¸âƒ£ Create Subscription**

* SNS â†’ Subscriptions â†’ Create Subscription
* Choose the **Topic**
* Choose **Protocol** (Email recommended)
* Enter your email
* Check inbox â†’ **Confirm Subscription**

---

### **3ï¸âƒ£ Create an S3 Bucket**

* Go to **S3 â†’ Create Bucket**
* Configure normally

---

### **4ï¸âƒ£ Configure S3 Event Notification**

* Open your S3 bucket
* Go to **Properties â†’ Event Notifications**
* Click **Create Event Notification**
* Enter:

  * Name
  * Event Type (e.g., â€œPUTâ€, â€œDELETEâ€)
  * Destination: **SNS Topic**
* Save

---

### **5ï¸âƒ£ Test the Setup**

* Upload or delete any object in S3
* SNS will instantly send an email notification to your subscribed email

---

## âœ”ï¸ Result

ğŸ‰ You will receive an **email notification** whenever an S3 event (upload/delete) occurs!

This demonstrates how SNS integrates with S3 for event-driven messaging.

---

## ğŸ› ï¸ Additional Tips (Optional Enhancements)

âœ”ï¸ Use **SQS** instead of Email for backend processing
âœ”ï¸ Trigger a **Lambda** function when an object is uploaded
âœ”ï¸ Add **message filtering** to send specific types of alerts
âœ”ï¸ Enable **SNS delivery status logging** for debugging

---

## ğŸ“˜ Summary

Amazon SNS is a powerful service that supports both **application-to-application** and **application-to-person** communication. By integrating SNS with S3, you can create automated, event-driven alerting systems easily.

---

# **LAB 2 â€“ AWS SNS & CloudWatch Alarm**

### **Send an SNS Email Notification When EC2 CPU Utilization Exceeds 50%**

This lab demonstrates how to configure **Amazon SNS** and **CloudWatch Alarms** to notify an end user when an **EC2 instanceâ€™s CPU Utilization goes above 50%**.

---

## ## ğŸ“Œ **Overview**

You will learn how to:

1. Create an **SNS Topic**
2. Create an **SNS Subscription** (Email Notification)
3. Launch an **EC2 Instance with Detailed Monitoring**
4. Configure a **CloudWatch Alarm**
5. Automatically send an **Email alert** when CPU > 50%

---

# ## âœ… **Step 1: Create an SNS Topic**

1. Go to **AWS Console â†’ SNS â†’ Topics**
2. Click **Create Topic**
3. Choose **Standard** type

   * Standard = high throughput, immediate delivery
4. Enter a **Topic Name** (Example: `EC2-CPU-Alerts`)
5. Leave all defaults
6. Click **Create Topic**

This topic acts as the **channel** where CloudWatch will publish alerts.

---

# ## âœ… **Step 2: Create a Subscription (Email)**

1. Open the SNS Topic you created
2. Click **Create Subscription**
3. Select:

   * **Protocol:** Email
   * **Endpoint:** Your Email Address
4. Click **Create Subscription**

### âš ï¸ Confirm Subscription

* You will receive an email from *AWS Notifications*
* Open it and click **Confirm Subscription**
* Status becomes **Confirmed** (not Pending)

This ensures SNS can send alerts to your email.

---

# ## âœ… **Step 3: Launch an EC2 Instance with Detailed Monitoring**

1. Go to **EC2 â†’ Instances â†’ Launch Instance**
2. Select any Amazon Linux/Ubuntu AMI
3. Choose instance type (t2.micro is fine)
4. Under **Monitoring**:

   * Enable **Detailed Monitoring** (1-minute metrics)
5. Configure storage, security group, key pair
6. Launch the instance

### Why enable Detailed Monitoring?

* CloudWatch basic monitoring = 5-minute intervals
* Detailed monitoring = 1-minute intervals
* Faster alarm triggers

---

# ## âœ… **Step 4: Create a CloudWatch Alarm for CPU Utilization**

1. Go to **CloudWatch â†’ Alarms â†’ Create Alarm**
2. Click **Select Metric**
3. Choose:

   * **EC2 â†’ Per-Instance Metrics**
   * Select **CPUUtilization**
   * Choose your EC2 instance
4. Click **Select Metric**

### Configure the Alarm Condition

5. Set the **Threshold type**: Static
6. Set the threshold:

   * **Greater than 50%**
7. Set **Period** to 1 minute (works well with detailed monitoring)

### Configure Notification

8. In **Notification Settings:**

   * Choose: **In Alarm**
   * Select the **SNS Topic** you created earlier (EC2-CPU-Alerts)

This means whenever CPU > 50%, CloudWatch will publish an alert to SNS.

---

# ## âœ… **Step 5: Create and Test the Alarm**

1. Review the settings
2. Click **Create Alarm**

### Testing the Alarm

To trigger CPU > 50%, you can SSH into the EC2 instance and run:

```bash
sudo yum install stress -y
stress --cpu 2
```

After a short period:

* CPU rises above 50%
* Alarm enters **ALARM** state
* CloudWatch sends the event to SNS
* SNS sends an **email notification** to your inbox

---

# ## ğŸ‰ **Result**

Whenever your EC2 instanceâ€™s CPU exceeds **50%**, you will receive a **real-time email alert** through AWS SNS.

This lab helps you understand:

* SNS Topics and subscriptions
* CloudWatch alarms
* Automated notifications
* Monitoring EC2 instances effectively

---

# **Amazon RDS (Relational Database Service)**

![AWS GIF](https://github.com/shyamdevk/AWS-Concepts-Labs/blob/images/rds.gif)

 ![Screenshot](https://github.com/shyamdevk/AWS-Concepts-Labs/blob/images/rds.png)

---

## ## ğŸ“Œ **Overview**

**Amazon RDS** is a **fully managed relational database service** provided by AWS.
It simplifies the process of **setting up, operating, and scaling** databases in the cloud by handling the heavy lifting such as **backups, patching, monitoring, and high availability**.

AWS manages the infrastructure so developers can focus on **application logic**, not database administration.

---

# ## ğŸš€ **Why Use Amazon RDS? (Benefits)**

### **1ï¸âƒ£ Fully Managed Service**

AWS automatically handles:

* Backups
* Patching
* Monitoring
* Hardware provisioning
* Failover

### **2ï¸âƒ£ Automated Backups**

Supports **daily automatic backups** + **point-in-time recovery** to restore any moment within a retention period.

### **3ï¸âƒ£ High Availability (Multi-AZ)**

* RDS automatically maintains a **standby replica** in another AZ.
* On failure, it performs **automatic failover**.
* Zero manual intervention.

### **4ï¸âƒ£ Read Replicas**

* Used for **high read performance**.
* Offload read queries from the primary database.
* Available for MySQL, MariaDB, PostgreSQL, and Aurora.

### **5ï¸âƒ£ Scalable**

* Scale **compute** (CPU/RAM) in minutes
* Scale **storage** (SSD/HDD) automatically or manually
* Support for **auto-scaling storage**

### **6ï¸âƒ£ Secure by Design**

* Run inside **Amazon VPC**
* Encrypted using **KMS**
* Access control using **IAM** + **Security Groups**

---

# ## ğŸ—‚ï¸ **Databases Supported by Amazon RDS**

| Engine                   | Description                                       |
| ------------------------ | ------------------------------------------------- |
| **MySQL**                | Open-source, widely used relational DB            |
| **PostgreSQL**           | Advanced open-source DB with rich features        |
| **MariaDB**              | MySQL-compatible community-driven DB              |
| **Oracle**               | Commercial enterprise database                    |
| **Microsoft SQL Server** | Popular enterprise database from Microsoft        |
| **Amazon Aurora**        | AWS-built, MySQL/PostgreSQL-compatible, 5Ã— faster |

---

# ## âš™ï¸ **Key Features of AWS RDS**

### ğŸ”¹ **Automated Backups**

Enabled by default, supports point-in-time recovery.

### ğŸ”¹ **Manual Snapshots**

Your own custom DB snapshots that persist until deleted.

### ğŸ”¹ **Multi-AZ Deployment**

For high availability and automatic failover.

### ğŸ”¹ **Read Replicas**

Scale read traffic and improve performance.

### ğŸ”¹ **Monitoring & Metrics**

* CloudWatch metrics
* Enhanced Monitoring
* Performance Insights

### ğŸ”¹ **Automatic Software Patching**

Keeps the database engine up to date.

### ğŸ”¹ **Parameter Groups & Option Groups**

Customize DB configurations easily.

---

# ## ğŸ¯ **When Should You Use RDS?**

Choose RDS when your application requires a **managed relational database system**, such as:

* Web and Mobile Applications
* E-commerce Platforms
* Banking & Financial Systems
* CRM / ERP Applications
* Data analytics and reporting
* Any application requiring ACID transactions

---

# ## ğŸ‰ **Why RDS Compared to EC2 or On-Prem?**

RDS removes the burden of:

* OS installation
* Database installation
* Patching
* Backups
* Server maintenance
* High availability setup

AWS automates these tasks so you focus on **application development**.

---
# ğŸ“˜ Exercise: Create a Database on EC2, Create a Table & Insert Data (MySQL)

This guide walks you through launching an EC2 instance, installing MySQL, creating a database, creating a table, and inserting sample data. A sample output screenshot is also included.

---

## ğŸš€ **Step 1: Launch an EC2 Instance**

* Choose **Ubuntu Server AMI** (24.04 or similar).
* Select instance type (t2.micro free tier).
* Configure storage & security group (allow SSH: port 22).
* Launch instance and SSH into it.

---

## ğŸ› ï¸ **Step 2: Install MySQL Server on Ubuntu**

Update system:

```bash
sudo apt update
```

Install MySQL:

```bash
sudo apt install mysql-server
```

Start MySQL shell:

```bash
sudo mysql
```

---

## ğŸ—„ï¸ **Step 3: Create a Database**

View existing databases:

```sql
SHOW DATABASES;
```

Create new DB:

```sql
CREATE DATABASE mydb;
```

Use the new DB:

```sql
USE mydb;
```

---

## ğŸ§± **Step 4: Create a Table**

```sql
CREATE TABLE students (
    id INT AUTO_INCREMENT PRIMARY KEY,
    name VARCHAR(50),
    course VARCHAR(50)
);
```

---

## ğŸ“¥ **Step 5: Insert Sample Data**

```sql
INSERT INTO students (name, course) VALUES
('Rahul', 'DevOps'),
('Ananya', 'Cybersecurity'),
('John', 'Cloud');
```

---

## ğŸ“¤ **Step 6: View Table Contents**

```sql
SELECT * FROM students;
```

### âœ” Sample Output:

 ![Screenshot](https://github.com/shyamdevk/AWS-Concepts-Labs/blob/images/output.png)

---

## ğŸ‰ Task Completed!

You have successfully:

* Launched an EC2 instance
* Installed MySQL
* Created a database
* Created a table
* Inserted multiple rows
* Retrieved data from the table


---

# ğŸ“˜ **AWS RDS Components**

Amazon RDS (Relational Database Service) is a **managed database service** that helps you easily create, operate, and scale databases in the cloud.

This guide explains the **core components** of RDS in a clean and simple way.

---

## ğŸš€ **1. DB Instance**

A **DB Instance** is the actual **database server** Amazon RDS creates and manages for you.

### ğŸ”¹ What it includes:

* Database Engine
* Storage (data)
* CPU & RAM (instance class)

### ğŸ”¹ Think of it like:

A **virtual machine running your database**.

### ğŸ”¹ Example:

Creating a MySQL DB instance â†’ AWS gives you a fully managed MySQL server.

---

## ğŸ› ï¸ **2. DB Engine**

The **DB Engine** is the **database software** running on the RDS instance.

### ğŸ”¹ Supported Engines:

* MySQL
* PostgreSQL
* MariaDB
* Oracle
* SQL Server
* Amazon Aurora

### ğŸ”¹ Example:

Choose **MySQL Engine** â†’ You can run MySQL queries, create tables, etc.

---

## âš™ï¸ **3. DB Instance Class**

The **DB Instance Class** defines the **hardware power** of your database instance.

### ğŸ”¹ It decides:

* CPU
* Memory (RAM)
* Network performance

### ğŸ”¹ Instance Class Examples:

| Instance Class | Power       | Use Case                  |
| -------------- | ----------- | ------------------------- |
| `db.t3.micro`  | Small       | Testing / Small apps      |
| `db.m5.large`  | Medium      | Production apps           |
| `db.r5.xlarge` | High Memory | Analytics / heavy queries |

### ğŸ”¹ Think of it like:

Choosing **the size and power of your computer**.

---

## ğŸ’½ **4. DB Instance Storage**

The storage used by your DB Instance to store:

* Data
* Indexes
* Logs

### ğŸ”¹ Storage Types:

| Storage Type                       | Description                   | Use Case        |
| ---------------------------------- | ----------------------------- | --------------- |
| **gp3 (General Purpose SSD)**      | Default, balanced performance | Most apps       |
| **io1/io2 (Provisioned IOPS SSD)** | High performance & IOPS       | Heavy workloads |
| Magnetic                           | Older type                    | Not recommended |

### ğŸ”¹ Additional Features:

* **Storage size**: e.g., 20GB, 100GB, 500GB
* **Storage autoscaling**: Automatically expands when needed

### ğŸ”¹ Example:

Setting **20GB gp3** = Your DB has a 20GB SSD disk.

---

## ğŸ§© **Quick Summary Table**

| Component             | Meaning                   | Simple Explanation  |
| --------------------- | ------------------------- | ------------------- |
| **DB Instance**       | The database server       | VM running your DB  |
| **DB Engine**         | The DB software           | MySQL? PostgreSQL?  |
| **DB Instance Class** | Hardware power            | CPU + RAM           |
| **DB Storage**        | Disk where DB stores data | SSD/HDD size & type |

---

## ğŸŒŸ **Extras (Useful Notes)**

### ğŸ” Managed Security

* Supports **VPC**, **Security Groups**, **KMS encryption**, **IAM authentication**.

### ğŸ“ˆ Scalability

* Vertical scaling via instance class upgrade
* Storage auto-scaling for growing data

### ğŸ›¡ï¸ Automated Backups

* Daily backups
* Point-in-time restore

### ğŸ’¥ High Availability (Optional)

* Multi-AZ Deployment â†’ Standby DB in another AZ

---

# ğŸ“˜ **Lab Exercise: Create and Access a Database using Amazon Aurora & RDS**

This lab guides you through creating a **MySQL Database** using **Amazon Aurora / RDS** and connecting to it through an EC2 instance.

---

## ğŸ **Objective**

* Create a managed database using **Amazon Aurora / RDS**
* Launch an EC2 instance
* Install a MySQL/MariaDB client
* Connect to the database using the DB endpoint

---

# ğŸš€ **STEP 1: Create the Database (Aurora / RDS)**

Follow these steps in the AWS Console:

### ğŸ”· **1. Go to RDS â†’ Databases â†’ Create Database**

You will see two creation methods:

* **Standard create**
* **Easy create**

âœ… Choose **Standard create**

---

### ğŸ”· **2. Choose the Engine**

* Select **MySQL** (or Aurora MySQL if needed)

---

### ğŸ”· **3. Choose Template**

* Select **Sandbox** (best for practice or free tier setups)

---

### ğŸ”· **4. Set Credentials**

* Master username â†’ e.g., `admin`
* Master password â†’ Choose a strong password
* Credential Management â†’ **Self-managed** (you store the password)

---

### ğŸ”· **5. Configure Instance & Storage**

* Choose instance type (example):

  * `db.t3.micro` (free-tier eligible)
* Storage type:

  * GP3 or default SSD
* Enable storage autoscaling (optional)

---

### ğŸ”· **6. Connectivity**

* **Do NOT connect to EC2 automatically**
* Choose your VPC
* Choose or create a Security Group
* Public access â†’ *No* (recommended)
* Authentication method â†’ **Password authentication**

---

### ğŸ”· **7. Monitoring**

* Standard monitoring is fine
* Detailed monitoring â†’ optional

---

### ğŸ”· **8. Create the Database**

Click **Create Database** and wait for the DB status to turn **Available**.

---

# ğŸ–¥ï¸ **STEP 2: Access the Database from EC2**

Follow these steps to connect to your RDS / Aurora DB server.

---

## ğŸ”· **1. Launch an EC2 Instance**

* OS recommended: **Amazon Linux 2023** or **Amazon Linux 2**
* Attach it to the **same VPC** where RDS was created

---

## ğŸ”· **2. Install MySQL / MariaDB Client**

### ğŸŸ¦ **If using Amazon Linux 2:**

```bash
sudo yum install mariadb105 -y
```

### ğŸŸ§ **If using Amazon Linux 2023 (AL2023):**

MySQL packages arenâ€™t included by default â†’ You must install via the MySQL repo:

```bash
sudo dnf install https://dev.mysql.com/get/mysql80-community-release-el9-1.noarch.rpm -y
sudo dnf clean all
sudo dnf makecache
sudo dnf install mysql-community-client -y
```

Verify:

```bash
mysql --version
```

---

## ğŸ”· **3. Edit RDS Security Group**

Allow inbound rule:

| Type         | Port | Source             |
| ------------ | ---- | ------------------ |
| MySQL/Aurora | 3306 | EC2 Security Group |

This allows EC2 to communicate with the DB.

---

## ğŸ”· **4. Connect to the Database**

Use the RDS **Endpoint** from the console.

### Syntax:

```bash
mysql -h <DB-ENDPOINT> -u <USERNAME> -p
```

### Example:

```bash
mysql -h database-1.cwfcqugwafxx.us-east-1.rds.amazonaws.com -u admin -p
```

After running the command, enter your DB password.

---

# ğŸ‰ **Youâ€™re Now Connected!**

You can now run SQL commands such as:

```sql
SHOW DATABASES;
CREATE DATABASE testdb;
USE testdb;
```

---

# ğŸ“ **Summary**

| Step  | What You Did                              |
| ----- | ----------------------------------------- |
| **1** | Created RDS/Aurora MySQL Database         |
| **2** | Configured credentials, storage & network |
| **3** | Launched EC2 and installed MySQL client   |
| **4** | Allowed EC2 â†’ RDS connectivity            |
| **5** | Connected to DB using endpoint            |

---
# ğŸŒ **Amazon Route 53**

![AWS GIF](https://github.com/shyamdevk/AWS-Concepts-Labs/blob/images/route53.gif)

### âœ… **What is Route 53?**

Amazon **Route 53** is a **highly available, scalable, and global DNS (Domain Name System) service** by AWS.
It helps map **domain names â†’ IP addresses** so users can reach websites and applications.

---

## â­ **Key Features**

### ğŸ”¹ **1. DNS Service**

* Converts domain name like `example.com` â†’ IP address.
* Ensures users reach your application correctly.

### ğŸ”¹ **2. Domain Registration**

* You can **buy, manage, and transfer** domain names directly from Route 53.

### ğŸ”¹ **3. Health Checks**

* Route 53 monitors your application or server.
* If the main server fails, it automatically routes traffic to a **healthy backup**.

### ğŸ”¹ **4. Traffic Routing Policies**

Route 53 can route traffic intelligently using:

| Policy                    | Description                         |
| ------------------------- | ----------------------------------- |
| **Simple Routing**        | One record â†’ one server             |
| **Weighted Routing**      | Split traffic based on weights      |
| **Latency-based Routing** | Sends user to lowest-latency region |
| **Failover Routing**      | Primary â†’ Secondary backup          |
| **Geolocation Routing**   | Based on userâ€™s geographic location |

---

## ğŸ“Œ **Why the name "Route 53"?**

Because **DNS works on port 53**.

---

## ğŸ“ **Short Note Summary**

**Route 53 = DNS + Domain Registration + Health Checks + Smart Traffic Routing.**

---

<br>

# ğŸŒ **DNS Resolution Explained**

### ğŸ§  **What is DNS?**

DNS (Domain Name System) translates domain names like `google.com` into IP addresses like `142.250.78.14`.

Itâ€™s basically the **â€œphonebook of the internet.â€**

---

# ğŸ”„ **DNS Resolution Flow (Step-by-Step)**

 ![Screenshot](https://github.com/shyamdevk/AWS-Concepts-Labs/blob/images/dns.png)

### **1ï¸âƒ£ Browser â†’ Checks Browser Cache**

* You type `www.example.com`
* Browser checks if the IP is already stored.

---

### **2ï¸âƒ£ Browser â†’ ISP DNS Resolver**

* If not cached, browser sends query to your **ISPâ€™s DNS Resolver** (like Airtel/Jio resolver).

---

### **3ï¸âƒ£ ISP DNS Resolver â†’ Local Cache Check**

* Resolver checks its own cache.
* If no entry â†’ goes to the **Root Server**.

---

### **4ï¸âƒ£ ISP Resolver â†’ Root Server**

* Root server doesnâ€™t know exact IP.
* It tells which **TLD server** to ask.

Example:
`example.com` â†’ go to **.com TLD server**

---

### **5ï¸âƒ£ TLD Server â†’ Authoritative Name Server**

* TLD server directs resolver to authoritative nameserver for that domain.

---

### **6ï¸âƒ£ Authoritative Name Server â†’ Returns IP**

* Contains the actual DNS records (A, AAAA, CNAME, MX).
* Responds with the real **IP address**.

---

### **7ï¸âƒ£ Resolver â†’ Caches Result**

* Stores the IP temporarily (TTL: Time To Live)
* Sends IP to browser

---

### **8ï¸âƒ£ Browser â†’ Connects to Web Server**

* Browser uses IP to load website.

---

# ğŸ“˜ **Complete Notes Summary**

### **Amazon Route 53**

* Manages domains + DNS + traffic routing
* Highly available and global
* Supports advanced routing (failover, weighted, latency)

### **DNS Resolution**

* Browser â†’ DNS Resolver â†’ Root â†’ TLD â†’ Name Server â†’ Browser
* Caching improves speed
* DNS makes internet human-friendly

---

# ğŸ“˜ **AWS Route 53 DNS Mapping Lab (GoDaddy Domain â†’ AWS ALB â†’ EC2)**

This repository contains a detailed step-by-step lab guide for mapping a GoDaddy-purchased domain name to an AWS website hosted on an EC2 instance behind an Application Load Balancer (ALB).
Finally, HTTPS is enabled using AWS Certificate Manager (ACM).

---

## ğŸ— **Architecture Overview**

```
GoDaddy Domain
      â†“ (Nameserver Update)
AWS Route 53 Hosted Zone
      â†“ (Alias Record)
Application Load Balancer (ALB)
      â†“
EC2 Instance
      â†“
Hosted Website
```

ğŸ‘‰ *(Insert final architecture image here)*

---

## ğŸ¯ **Lab Objectives**

* Import a GoDaddy-purchased domain into AWS Route 53
* Create a Public Hosted Zone
* Map the domain to an Application Load Balancer
* Validate domain ownership
* Issue an SSL certificate using AWS Certificate Manager
* Enable HTTPS on the Load Balancer
* Redirect HTTP â†’ HTTPS

---

## ğŸ“ **Prerequisites**

This lab assumes the following steps are already completed:

âœ” EC2 instance created
âœ” Website hosted and running
âœ” Application Load Balancer created
âœ” Domain name purchased from GoDaddy
âœ” EC2 added to Target Group â†’ ALB

---

# ğŸ§ª **LAB STEPS**

---

# ğŸ”¹ **STEP 1: Create a Public Hosted Zone in Route 53**

1. Open **AWS Console â†’ Route 53 â†’ Hosted zones**
2. Click **Create hosted zone**
3. Enter your domain name (same as GoDaddy purchase)
4. Type: **Public hosted zone**
5. Click **Create**

Route 53 automatically creates:

* SOA record
* NS records (Name Servers)

ğŸ“Œ *You will copy these NS values to GoDaddy.*

---

# ğŸ”¹ **STEP 2: Update GoDaddy to Use AWS Name Servers**

1. Login to GoDaddy
2. Navigate to **My Products â†’ Your Domain â†’ Manage DNS**
3. Scroll to **Nameservers â†’ Change**
4. Choose **Custom nameservers**
5. Enter the **4 AWS Route 53 nameservers**

Example:

```
ns-123.awsdns-45.com
ns-456.awsdns-78.org
ns-789.awsdns-12.net
ns-321.awsdns-90.co.uk
```

6. Save changes
7. Wait for DNS propagation (10â€“60 mins, sometimes 24 hrs)

ğŸ“Œ Your GoDaddy domain is now managed by Route 53.

---

# ğŸ”¹ **STEP 3: Get Your Load Balancer DNS Name**

1. Go to **AWS Console â†’ EC2 â†’ Load Balancers**
2. Select your Application Load Balancer
3. Copy the **DNS Name**, for example:

```
myapp-alb-1234567.ap-south-1.elb.amazonaws.com
```

You will map your domain to this ALB.

---

# ğŸ”¹ **STEP 4: Create DNS Records in Route 53**

### âœ… **Record 1: A Record (Alias â†’ ALB)**

**Purpose:** Map `yourdomain.com` to ALB.

1. Open **Route 53 â†’ Hosted zone**
2. Click **Create record**
3. Settings:

| Field        | Value           |
| ------------ | --------------- |
| Record Name  | *(leave empty)* |
| Type         | A               |
| Alias        | Yes             |
| Alias Target | Choose your ALB |

4. Click **Create Record**

This creates:

```
yourdomain.com â†’ ALB â†’ EC2 â†’ Website
```

---

### âœ… **Record 2: CNAME (www â†’ root domain)**

**Purpose:** Allow users to access [www.yourdomain.com](http://www.yourdomain.com).

1. Create a new record
2. Type: **CNAME**
3. Name: `www`
4. Value:

```
yourdomain.com
```

5. Save

---

# ğŸ”¹ **STEP 5: Request an SSL Certificate in ACM**

### 1. Open **AWS Certificate Manager (ACM)**

Make sure to choose the **same region as ALB**.

### 2. Click **Request Certificate â†’ Request a Public Certificate**

Add:

```
yourdomain.com
www.yourdomain.com
```

Click **Next**

### 3. Validation Method:

âœ” **DNS Validation**

Click **Review â†’ Request**

### 4. Add DNS Validation Records

ACM shows CNAME validation records.

Click:

```
Create records in Route 53
```

Route 53 automatically adds the validation DNS records.

Status changes:

```
Pending validation â†’ Issued
```

---

# ğŸ”¹ **STEP 6: Attach SSL Certificate to the Load Balancer**

1. Go to **EC2 â†’ Load Balancers**
2. Select ALB
3. Open **Listeners** tab
4. Click **Add Listener**
5. Configure:

| Setting        | Value                   |
| -------------- | ----------------------- |
| Protocol       | HTTPS                   |
| Port           | 443                     |
| Certificate    | Choose ACM certificate  |
| Default Action | Forward to Target Group |

6. Save

ğŸ”’ Your site now supports HTTPS.

---

# ğŸ”¹ **STEP 7: Redirect HTTP â†’ HTTPS (Optional but Recommended)**

1. Select **HTTP (80)** listener
2. Click **Edit**
3. Change action to:

```
Redirect to â†’ HTTPS:443
```

4. Save

Now:

```
http://yourdomain.com â†’ https://yourdomain.com
```

---

# ğŸ”¹ **STEP 8: Test the Website**

Open:

* âœ” [https://yourdomain.com](https://yourdomain.com)
* âœ” [https://www.yourdomain.com](https://www.yourdomain.com)

Check:

* SSL padlock visible
* Correct website loads
* Redirect works

---

# ğŸ§¼ **Cleanup (Optional)**

* Delete Route 53 Hosted Zone
* Delete ACM certificate
* Remove DNS records
* Delete ALB
* Terminate EC2 instance

---

# ğŸ“‚ **Repository Structure Suggestion**

```
ğŸ“ aws-route53-dns-mapping-lab
â”‚â”€â”€ README.md
â”‚â”€â”€ images/
â”‚     â””â”€â”€ architecture-diagram.png
â”‚â”€â”€ steps/
â”‚     â””â”€â”€ route53-setup.txt
â”‚     â””â”€â”€ acm-https.txt
â”‚     â””â”€â”€ dns-records.txt
```

---

# ğŸ“„ **Conclusion**

You successfully:

* Imported a GoDaddy domain into Route 53
* Mapped it to an AWS Application Load Balancer
* Configured DNS records
* Validated domain ownership
* Enabled HTTPS using ACM
* Redirected all traffic to secure HTTPS

Your domain now loads your EC2-hosted website securely through the ALB.

---

# ğŸŒ **AWS CloudFront**

![AWS GIF](https://github.com/shyamdevk/AWS-Concepts-Labs/blob/images/cloudfront.gif)

> A simple, clean and beginner-friendly explanation of AWS CloudFront.
> Suitable for notes, seminars, and GitHub documentation.

---

## ğŸš€ **What is AWS CloudFront?**

AWS CloudFront is a **Content Delivery Network (CDN)** service that delivers web content like images, videos, HTML, CSS, JS, and APIs **faster** using a global network of **Edge Locations**.

ğŸ‘‰ **CloudFront = Global CDN + Caching + Fast Delivery + Security**

---

## ğŸ—ºï¸ **CloudFront Architecture (Diagram Placeholder)**

*Add your image here*

```
ğŸ“Œ Place CloudFront architecture diagram here
```

---

## â­ **Why Use CloudFront? (Advantages)**

### âœ” **1. Faster Content Delivery**

Delivers content from the nearest **Edge Location**, reducing latency.

### âœ” **2. Caching Improves Performance**

Caches images, videos, static files â†’ reduces origin server load.

### âœ” **3. High Security**

* HTTPS support
* AWS Shield (DDoS protection)
* AWS WAF integration
* Signed URLs / Cookies

### âœ” **4. Very Cost-Effective**

Less data transferred from S3/EC2 â†’ lower AWS bill.

### âœ” **5. Scalable & Reliable**

Handles millions of requests globally without manual scaling.

---

## ğŸ”§ **How CloudFront Works (Simple Flow)**

*Add your flow diagram here*

```
User â†’ Edge Location â†’ Cache Hit? â†’ If No â†’ Origin (S3/EC2/ALB) â†’ Cached â†’ User
```

### ğŸ“Œ Steps:

1. User requests a file (HTML, image, video, API).
2. Request goes to nearest **CloudFront Edge Location**.
3. If cached â†’ returned instantly (**cache hit**).
4. If not cached â†’ CloudFront fetches from **Origin**.
5. Caches it â†’ sends to the user.

---

## ğŸ§© **CloudFront Components**

### ğŸ¢ **1. Distribution**

The main configuration for CloudFront.

### ğŸ“¦ **2. Origin**

The real backend:

* Amazon **S3**
* **EC2**
* **Application Load Balancer**
* Custom server

### ğŸŒ **3. Edge Locations**

Global data centers for caching content.

### âš™ **4. Cache Behavior**

Controls:

* Which files to cache
* Allowed HTTP methods
* HTTP vs HTTPS
* TTL (cache time)

---

## ğŸ” **Security Features**

| Feature                         | Purpose                                    |
| ------------------------------- | ------------------------------------------ |
| **HTTPS / TLS**                 | Encrypts data                              |
| **AWS WAF**                     | Blocks attacks (SQLi, XSS, bots)           |
| **AWS Shield**                  | DDoS protection                            |
| **Signed URLs**                 | Restrict access to premium/private content |
| **Origin Access Control (OAC)** | Secure private S3 buckets                  |

---

## ğŸ¯ **Use Cases of CloudFront**

| Use Case             | Example                     |
| -------------------- | --------------------------- |
| Website Acceleration | Faster global websites      |
| Video Streaming      | OTT platforms               |
| Image Delivery       | E-commerce product images   |
| API Caching          | Faster API calls            |
| Secure Delivery      | Paid content, private files |

---

## ğŸ“ **Quick Summary**

* CloudFront is AWSâ€™s **CDN** service.
* Delivers content quickly using **edge locations**.
* Supports caching, security, HTTPS, WAF, and signed URLs.
* Works best with **S3**, **EC2**, **ALB**, **API Gateway**.
* Very useful for global websites, APIs, images, videos.

---
# ğŸŒ **AWS CloudFront â€” Hands-On Lab**

> This lab helps you understand how to deliver content using **AWS CloudFront** with an **Application Load Balancer (ALB)** hosting a sample website on EC2.

---

## ğŸ“˜ **Lab Overview**

In this lab you will:

1. Launch an EC2 instance with a sample webpage
2. Create a Load Balancer for the EC2 instance
3. Create a CloudFront Distribution
4. Connect CloudFront to the Load Balancer as the Origin
5. Access your website using the CloudFront global CDN URL

---

# ğŸ **Step 1 â€” Launch EC2 Instance With Sample Webpage**

Use the following **User Data** script when launching EC2:

```bash
#!/bin/bash
yum update -y
yum install -y httpd
systemctl start httpd
systemctl enable httpd

echo "<h1>Welcome to My EC2 Website</h1>" > /var/www/html/index.html
echo "<p>This website is served through an Application Load Balancer.</p>" >> /var/www/html/index.html
```

âœ” This creates a simple webpage
âœ” Apache starts automatically

---

# ğŸ—ï¸ **Step 2 â€” Create an Application Load Balancer (ALB)**

### Follow these steps:

1. Open **EC2 Console â†’ Load Balancers**
2. Click **Create Load Balancer â†’ Application Load Balancer**
3. Set:

   * **Scheme:** Internet-facing
   * **IP type:** IPv4
4. **Listeners:** HTTP (port 80)
5. **Availability Zones:** Select at least 2
6. **Target Group:**

   * Create a new target group
   * Register your EC2 instance

After creation, open the ALB **DNS name** in your browser to verify the website loads.

---

# ğŸŒ **Step 3 â€” Create CloudFront Distribution**

### Steps:

1. Open **CloudFront Console**
2. Click **Create Distribution**
3. In **Origin Domain**, choose your **Load Balancer**
4. Keep **viewer protocol policy** as:

   ```
   Redirect HTTP to HTTPS  (recommended)
   ```

   If your ALB does not support HTTPS yet â†’ you can change this later.

---

# ğŸ›ï¸ **Step 4 â€” (Optional Fix) Edit Origin Settings**

If your Load Balancer only supports **HTTP**, CloudFront HTTPS may fail.

To fix this:

1. Open the Distribution
2. Go to **Origins â†’ Edit**
3. Change:

   * **Origin Protocol Policy:** HTTP Only
4. Save changes
5. CloudFront will deploy the update (takes 3â€“5 minutes)

---

# ğŸ”— **Step 5 â€” Access Your Website Through CloudFront**

After the distribution status shows **Enabled**, copy the CloudFront domain:

```
https://d123example.cloudfront.net
```

Paste it in your browser â†’ your EC2 website will load from **global edge locations**.

ğŸ‰ Congratulations!
You are now serving your website using **AWS CloudFront CDN + Load Balancer + EC2**.

---

# ğŸ“ **Summary**

| Component  | Purpose                              |
| ---------- | ------------------------------------ |
| EC2        | Hosts your sample webpage            |
| ALB        | Distributes traffic across instances |
| CloudFront | Serves content fast using global CDN |

CloudFront improves performance, caching, scalability, and global delivery.

---
# ğŸŒ **LAB: Host Static Website on S3 + Deliver via CloudFront (With OAC)**

> This lab teaches you how to host a static website on an **S3 bucket** and deliver it globally using **AWS CloudFront** with **Origin Access Control (OAC)**.
>
> Also includes the fix for **CSS, JS, images not loading (403 AccessDenied)** by applying the correct S3 bucket policy.

---

## ğŸ“ **Folder Structure Example**

```
index.html
assets/
   â”œâ”€â”€ css/
   â””â”€â”€ js/
images/
   â”œâ”€â”€ logo.png
   â””â”€â”€ banner.jpg
```

---

# ğŸ§ª **STEPS**

---

# âœ… **Step 1 â€” Create an S3 Bucket**

1. Open **AWS â†’ S3**
2. Click **Create bucket**
3. Bucket name: `buckerr989898`
4. Leave **Block Public Access ON** (required for OAC)
5. Create bucket

---

# âœ… **Step 2 â€” Upload Website Files**

Upload:

* `index.html`
* `assets/` folder
* `images/` folder

---

# âœ… **Step 3 â€” Enable Static Website Hosting**

Inside **Bucket â†’ Properties**:

1. Enable **Static website hosting**
2. Set:

   * Index document: `index.html`
   * Error document: `index.html` (optional for SPA)

---

# âœ… **Step 4 â€” Create CloudFront Distribution**

1. Open **CloudFront** â†’ **Create Distribution**
2. Origin domain â†’ Choose the S3 bucket
3. **Origin Access Control (OAC)** â†’ *Enable (recommended)*
4. Create distribution

---

# âœ… **Step 5 â€” Apply Correct S3 Bucket Policy (Fix CSS/JS/Images 403 Error)**

This policy allows **CloudFront** to load:

âœ” index.html
âœ” asset files
âœ” image files
âœ” CSS / JS / PNG / JPG / SVG

### âœ” **Final Working Bucket Policy (OAC)**

```json
{
  "Version": "2012-10-17",
  "Statement": [
    {
      "Sid": "AllowCloudFrontOACAccess",
      "Effect": "Allow",
      "Principal": {
        "Service": "cloudfront.amazonaws.com"
      },
      "Action": "s3:GetObject",
      "Resource": "arn:aws:s3:::buckerr989898/*",
      "Condition": {
        "StringEquals": {
          "AWS:SourceArn": "arn:aws:cloudfront::526888234336:distribution/EBEJZQVVTMTHA"
        }
      }
    }
  ]
}
```

ğŸ‘‰ **This makes everything under the bucket public to CloudFront**, including:

* `assets/css/font-awesome.min.css`
* `assets/js/*`
* `images/*`

No need to change any additional permissions.

---

# âœ… **Step 6 â€” Invalidate CloudFront Cache**

After updating the policy:

1. CloudFront â†’ **Invalidations**
2. Create **new invalidation**
3. Enter:

```
/*
```

This forces CloudFront to fetch new files.

---

# âœ… **Step 7 â€” Test the Website**

Open the CloudFront domain:

```
https://dxxxxxx.cloudfront.net
```

Now your:

âœ” CSS loads
âœ” JS loads
âœ” Images load
âœ” Full website works ğŸ‰

---

# ğŸ“Œ **Common Issue: Only index.html Loads**

This happens when:

âŒ assets/ or images/ folders are private
âŒ wrong bucket policy
âŒ CloudFront not authorized to read objects

The above **OAC bucket policy fixes this 100%**.

---

# ğŸ‰ **Lab Completed Successfully**

You have now hosted a static website on **S3** and delivered it via **CloudFront** with correct permissions.

# ğŸŒ **LAB: Give CloudFront Access to a Private S3 Bucket & Host Website**

This lab explains **how to host a static website in a PRIVATE S3 bucket** and **allow CloudFront to access it securely using OAC (Origin Access Control)**.

---

## ğŸ§ª **LAB NAME:**

**Host Website on Private S3 Bucket Using CloudFront (OAC)**

---

# âœ… **STEPS**

## **1ï¸âƒ£ Create an S3 Bucket (Private)**

1. Go to **AWS S3 Console â†’ Create bucket**
2. Bucket name example:

   ```
   buckerr989898
   ```
3. Keep **Block Public Access = ON** (required for private hosting)
4. Upload your files:

   * `index.html`
   * `assets/` folder (CSS/JS)
   * `images/` folder

---

## **2ï¸âƒ£ Create CloudFront Distribution**

1. Go to **CloudFront Console**
2. Click **Create Distribution**
3. **Origin domain:** Choose your S3 bucket
4. Under "Origin access":

   * Select **Origin Access Control (Recommended)**
5. Save â†’ Create distribution.

This makes CloudFront the only allowed service that can read your bucket.

---

## **3ï¸âƒ£ Apply Bucket Policy to Allow CloudFront Access**

Use the policy below (this is the final working version for your case):

```json
{
  "Version": "2012-10-17",
  "Statement": [
    {
      "Sid": "AllowCloudFrontOACAccess",
      "Effect": "Allow",
      "Principal": {
        "Service": "cloudfront.amazonaws.com"
      },
      "Action": "s3:GetObject",
      "Resource": "arn:aws:s3:::buckerr989898/*",
      "Condition": {
        "StringEquals": {
          "AWS:SourceArn": "arn:aws:cloudfront::526888234336:distribution/EBEJZQVVTMTHA"
        }
      }
    }
  ]
}
```

### âœ” This policy allows CloudFront to read:

* `index.html`
* `assets/**`
* `images/**`
* Any future files inside the bucket

Because the `/*` wildcard covers **all folders** inside S3.

---

## **4ï¸âƒ£ Disable S3 Public Access Permissions**

You **must not make your files public manually**.

Leave:

* **Bucket Public Access Block = ON**
* No public ACLs
* No public objects

CloudFront â†’ OAC â†’ is responsible for access.

---

## **5ï¸âƒ£ Invalidate CloudFront Cache**

After uploading new files or updating the policy:

Go to:
**CloudFront â†’ Invalidations â†’ Create Invalidation â†’ `/*`**

This forces CloudFront to fetch fresh content.

---

## **6ï¸âƒ£ Test the Website**

Open your CloudFront domain:

```
https://dxxxxxxxxxxxx.cloudfront.net
```

Your entire website (HTML + assets + images) will now load even though the S3 bucket is **fully private**.

---

# ğŸ“ **Summary for Notes**

### âœ” Private S3 bucket

Public access is blocked.

### âœ” CloudFront OAC

Securely accesses the bucket on your behalf.

### âœ” Bucket Policy

Allows CloudFront distribution to read all files.

### âœ” CloudFront Domain

Used to load the website.

### âœ” Static Website Hosting

Not required â€” CloudFront reads objects directly.

---

# ğŸ‰ Final Output

With this configuration:

* Website loads from CloudFront
* S3 bucket stays **100% private**
* All folders (`assets/`, `images/`, etc.) work
* No 403 errors

---
# ğŸ“ Amazon EFS (Elastic File System)

![AWS GIF](https://github.com/shyamdevk/AWS-Concepts-Labs/blob/images/efs.gif)

Amazon **EFS** is a **fully managed, scalable, shared file storage** service for **Linux-based applications**.  
It allows **multiple EC2 instances** to access the **same files at the same time** using the **NFS protocol**.

---

## ğŸš€ Why EFS?
EFS works like a **shared network folder**.  
If one EC2 writes a file, **all other EC2s can immediately see it**.  
You donâ€™t need to manage storage size â€” EFS **grows and shrinks automatically**.

---

## â­ Key Features
- ğŸ”„ **Auto-scaling** â€“ Storage expands with your data  
- ğŸ¤ **Shared access** â€“ Many EC2 instances can mount it  
- ğŸ›¡ï¸ **Highly Available** â€“ Data stored across all AZs  
- ğŸ” **Secure** â€“ Supports encryption at rest & in transit  
- ğŸ’¼ **Fully Managed** â€“ No servers, no maintenance  
- ğŸ’° **Pay-as-you-go** â€“ Pay only for the space you use  

---

## ğŸ“˜ How EFS Works (Simple)
1. You create an **EFS file system** in AWS.  
2. AWS automatically creates **mount targets** in each Availability Zone.  
3. EC2 instances connect to EFS using **NFSv4** protocol.  
4. All EC2 instances share the **same data** inside EFS.

---

## ğŸ§° Common Use Cases
- ğŸŒ Web servers (Apache/Nginx) sharing the same content  
- ğŸ“ WordPress / CMS shared uploads folder  
- ğŸ“Š Big data & analytics processing  
- ğŸ§‘â€ğŸ’» Shared home directories for multiple users  
- ğŸ“¦ ECS/EKS containers needing shared storage  

---

## ğŸ”„ EFS vs EBS (Quick Comparison)
| Feature | **EFS** | **EBS** |
|--------|---------|---------|
| Type | File storage | Block storage |
| Access | Many EC2 instances | Single EC2 |
| Scaling | Automatic | Fixed size |
| Use Case | Shared data | OS disk, DB storage |

---

## ğŸ› ï¸ Basic Mount Commands (Optional)
Install NFS tools:
```bash
sudo yum install -y nfs-utils   # Amazon Linux
sudo apt install -y nfs-common  # Ubuntu/Debian
````

Create mount directory:

```bash
sudo mkdir /efs
```

Mount EFS:

```bash
sudo mount -t nfs4 fs-xxxx.efs.<region>.amazonaws.com:/ /efs
```

---

## ğŸ¯ Summary

Amazon EFS is best when you need:
âœ” Shared storage
âœ” Auto-scaling
âœ” Multi-AZ durability
âœ” Easy Linux + EC2 integration

Simple, scalable, and perfect for distributed applications.

---

# ğŸ§ª LAB: Configure AWS EFS & Mount on Two EC2 Instances

This lab demonstrates how to **create an Amazon EFS file system**, mount it on **two EC2 instances**, and verify that **both instances can access the same shared storage**.

---

# ğŸ“Œ **ğŸ¯ Objective**
- Create an **EFS File System**  
- Create **two EC2 instances**  
- Mount the **same EFS** on both instances (using different mount directories)  
- Verify **shared access** by creating a file from one instance and accessing it from the other

---

# ğŸ—ï¸ Step 1 â€” Create EFS File System
1. Go to **EFS Console**
2. Click **Create File System**
3. Choose:  
   - âœ… *Recommended settings* (or customize if needed)  
4. Click **Create**
5. EFS file system will be created along with **Mount Targets** in each AZ.

---

# ğŸ” Step 2 â€” Configure Security Group
To mount EFS using NFS:

### âœ” Ensure the EFS Security Group allows:
- **Inbound Rule:**  
  - *Type:* NFS  
  - *Port:* 2049  
  - *Source:* EC2 Instance Security Group

This ensures EC2 instances can connect to EFS.

---

# ğŸ’» Step 3 â€” Launch Two EC2 Instances
1. Create **two Linux EC2 instances**
2. Attach them to:
   - Same VPC  
   - Same or reachable Subnets  
   - Security Groups that allow NFS communication  

---

# ğŸ“Œ Step 4 â€” Mount EFS on EC2 Instance 1
1. Go to **EFS Console â†’ Your EFS â†’ Attach**
2. Choose **Mount via DNS**
3. Copy the NFS client command they provide

Example mount command:
```bash
sudo mount -t nfs4 -o nfsvers=4.1,rsize=1048576,wsize=1048576,hard,timeo=600,retrans=2,noresvport fs-06ecbb4def899ef60.efs.us-east-1.amazonaws.com:/ <directory-name>
````

### Create a mount directory:

```bash
sudo mkdir /efs1
```

### Mount EFS:

```bash
sudo mount -t nfs4 -o nfsvers=4.1,rsize=1048576,wsize=1048576,hard,timeo=600,retrans=2,noresvport fs-06ecbb4def899ef60.efs.us-east-1.amazonaws.com:/ /efs1
```

---

# ğŸ“Œ Step 5 â€” Mount EFS on EC2 Instance 2

Repeat the same steps on the **second instance**.

### Create a different directory:

```bash
sudo mkdir /efs2
```

### Mount EFS:

```bash
sudo mount -t nfs4 -o nfsvers=4.1,rsize=1048576,wsize=1048576,hard,timeo=600,retrans=2,noresvport fs-06ecbb4def899ef60.efs.us-east-1.amazonaws.com:/ /efs2
```

---

# ğŸ“ Step 6 â€” Test Shared Access (Important)

### On Instance 1:

```bash
cd /efs1
sudo touch testfile.txt
sudo mkdir testfolder
```

### On Instance 2:

```bash
cd /efs2
ls
```

### ğŸŸ¢ You should see:

```
testfile.txt
testfolder
```

This confirms EFS is **mounted successfully** and **shared** between both EC2 instances.

---

# âœ… **Lab Completed!**

You have successfully:

* Created an EFS File System
* Mounted it on two EC2 instances
* Verified shared file access

This setup is commonly used in:

* Load-balanced web servers
* CMS applications (WordPress shared uploads)
* Any distributed system needing shared file storage

---
# ğŸ³ **AWS ECS**
 ![Screenshot](https://github.com/shyamdevk/AWS-Concepts-Labs/blob/images/ecs1.gif)

A beginner-friendly, easy-to-understand explanation of **Containerization**, **Docker**, **AWS ECS**, and a **simple hands-on lab**.

---

# ğŸ“¦ **1. Introduction to Containerization**

## ğŸ”¹ What is Containerization?

Containerization is the process of packaging an application along with all its dependencies (libraries, runtime, config files) into a lightweight, portable unit called a **container**.

### â­ Benefits of Containerization

* âš¡ Fast deployment
* ğŸ§© Works the same everywhere (no environment conflicts)
* ğŸ” Easy scaling
* ğŸª¶ Lightweight (uses less resources than VMs)
* ğŸš€ Portable across systems (laptop â†’ server â†’ cloud)

## ğŸ³ Docker (Most Popular Container Tool)

### ğŸ§± Docker Image

Blueprint of the application.

### ğŸŸ¦ Docker Container

Running instance of the Docker image.

---

# ğŸŸ¦ **2. What is AWS ECS (Elastic Container Service)?**
 ![Screenshot](https://github.com/shyamdevk/AWS-Concepts-Labs/blob/images/ecs.gif)

AWS ECS is a fully managed **container orchestration service** used to **run, manage, and scale Docker containers**.

Think of ECS as a service that takes care of:

* Scheduling containers
* Starting/stopping tasks
* Scaling automatically
* Load balancing your app
* Handling networking

---

# ğŸ§± **3. ECS Building Blocks (Simple Explanation)**

| Component           | Meaning                                                           |
| ------------------- | ----------------------------------------------------------------- |
| **Cluster**         | Group of resources running containers (EC2 or Fargate)            |
| **Task Definition** | Blueprint of how container should run (image, CPU, memory, ports) |
| **Task**            | A running container                                               |
| **Service**         | Ensures the required number of tasks are always running           |
| **ECR**             | AWS container registry to store Docker images                     |

---

# ğŸŸ© **4. ECS Launch Types**

### ğŸ”¹ 1. **EC2 Launch Type**

* Containers run on your EC2 instances
* You manage the servers
* More control, but more work

### ğŸ”¹ 2. **Fargate Launch Type**

* Serverless containers
* No EC2 needed
* AWS manages everything
* Best for beginners

---

# ğŸŒ€ **5. ECS Workflow (Easy Diagram)**

```
Developer â†’ Docker Image â†’ Push to ECR
                â†“
             ECS Cluster
                â†“
        ECS Task Definition
                â†“
        ECS Service (Auto-scaling)
                â†“
            Running Tasks
                â†“
   ALB Load Balancer â†’ Users
```

---

# ğŸŸ§ **6. Use Cases of ECS**

* Microservices
* Web applications
* APIs
* Background jobs
* Log processing systems
* CI/CD workloads

---

Got it!
Here is the **final README.md content**, fully formatted, clean, and ready for you to **copy & paste directly**.

---

# **AWS ECS â€” NGINX Lab (Using Amazon Linux CLI & ECR)**

A straightforward, fixed-version lab to **pull `nginx:latest` on an Amazon Linux host, tag it, push to ECR, and deploy on ECS (Fargate)**.
This version includes **all corrected commands** based on your errors.

---

## **Prerequisites**

* AWS account
* Amazon Linux EC2 (Amazon Linux 2023 or 2)
* Docker installed
* AWS CLI configured (or IAM role on EC2)
* ECR repository (we will create if not exists)

---

# **0 â€” Check OS Version (important)**

```bash
cat /etc/os-release
```

---

# **1 â€” Install Docker**

## **If Amazon Linux 2023:**

```bash
sudo dnf update -y
sudo dnf install docker -y
sudo systemctl start docker
sudo systemctl enable docker
sudo usermod -aG docker ec2-user
```

## **If Amazon Linux 2:**

```bash
sudo yum update -y
sudo amazon-linux-extras install docker -y
sudo service docker start
sudo usermod -aG docker ec2-user
```

Logout and login again.

Check Docker:

```bash
docker ps
```

---

# **2 â€” Configure AWS Credentials (if needed)**

If you saw this error earlier:

```
Unable to locate credentials
```

Run:

```bash
aws configure
```

Enter:

* Access Key ID
* Secret Key
* Region (us-east-1)
* Output: json

---

# **3 â€” Pull the NGINX Image (from Docker Hub)**

```bash
docker pull nginx:latest
```

Verify:

```bash
docker images
```

---

# **4 â€” Create an ECR Repository (if not exists)**

```bash
aws ecr describe-repositories --repository-names ecs-demo --region us-east-1 >/dev/null 2>&1 || \
aws ecr create-repository --repository-name ecs-demo --region us-east-1
```

---

# **5 â€” Login to ECR (Correct Syntax)**

```bash
aws ecr get-login-password --region us-east-1 \
| docker login --username AWS --password-stdin 526888234336.dkr.ecr.us-east-1.amazonaws.com
```

You should see:

```
Login Succeeded
```

---

# **6 â€” Tag the Local Image With ECR Repo URI**

```bash
docker tag nginx:latest 526888234336.dkr.ecr.us-east-1.amazonaws.com/ecs-demo:latest
```

Check tags:

```bash
docker images
```

---

# **7 â€” Push Image to ECR**

```bash
docker push 526888234336.dkr.ecr.us-east-1.amazonaws.com/ecs-demo:latest
```

---

# **8 â€” Create ECS Cluster (Fargate)**

AWS Console â†’ ECS â†’ Clusters â†’ Create Cluster

* **Networking Only (Fargate)**
* Name: `ecs-nginx-cluster`

---

# **9 â€” Create ECS Task Definition**

Task Definitions â†’ Create New

* **Launch Type:** Fargate
* **CPU:** 256
* **Memory:** 512
* **Add container**

Container Settings:

* Name: `nginx-container`
* Image:

  ```
  526888234336.dkr.ecr.us-east-1.amazonaws.com/ecs-demo:latest
  ```
* Port: **80**

Create.

---

# **10 â€” Create ECS Service**

Cluster â†’ Create Service

* Launch Type: Fargate
* Service Name: `nginx-service`
* Tasks: 1

Networking:

* Select VPC
* Select **public subnets**
* Auto-assign public IP â†’ **ENABLE**

Create service.

---

# **11 â€” Verify Deployment**

1. Go to ECS â†’ Cluster â†’ Tasks
2. Task status: **RUNNING**
3. Check **Public IP**
4. Open in browser:

```
http://<public-ip>
```

You should see the **NGINX Welcome Page** ğŸ‰

---

# **Troubleshooting**

### **Error: unknown flag: --shyamdev**

Cause: Wrong docker login command
Fix: Always use

```bash
--username AWS --password-stdin
```

### **Error: An image does not exist locally**

Cause: You didnâ€™t tag local image
Fix:

```bash
docker tag nginx:latest <ecr-uri>
```

### **Error: Unable to locate credentials**

Fix:

```bash
aws configure
```

### **Push denied**

IAM role/user missing permissions.

---

# **Final Flow Summary**

```
Amazon Linux â†’ docker pull nginx â†’ tag â†’ ECR login â†’ docker push â†’ ECS (Fargate) â†’ Public IP â†’ NGINX page
```

---


# ğŸ“˜ **AWS SQS - Amazon Simple Queue Service**

![Screenshot](https://github.com/shyamdevk/AWS-Concepts-Labs/blob/images/sqs.gif)
---

## ğŸ§­ **What is Amazon SQS?**

**Amazon Simple Queue Service (SQS)** is a **fully managed message queue** service that allows different parts of an application to communicate **asynchronously**.

â¡ï¸ **SQS = Temporary storage for messages until a worker processes them**

**Why use it?**

* To **decouple** microservices
* To **avoid system overload**
* To **ensure messages are never lost**

---

# ğŸŸ¦ **Types of SQS Queues**

## ğŸ”¹ **1. Standard Queue (Default)**

* Supports **unlimited throughput**
* **At-least-once delivery**
* **Best-effort ordering** (not guaranteed)
* Suitable for high-scale systems
  â¡ï¸ Use when *ordering is not important*.

## ğŸ”¹ **2. FIFO Queue (First-In-First-Out)**

* **Strict ordering** guaranteed
* **Exactly-once processing**
* Lower throughput than Standard
* Supports â€œ**Message Group ID**â€ for parallel processing
  â¡ï¸ Use when *order matters* (payments, transactions).

---

# ğŸš€ **How SQS Works (Simple Flow)**

1ï¸âƒ£ **Producer sends message â†’ SQS Queue**
2ï¸âƒ£ SQS stores the message durably
3ï¸âƒ£ **Consumer polls** the queue
4ï¸âƒ£ Consumer processes the message
5ï¸âƒ£ Consumer **deletes message** from queue

â¡ï¸ If not deleted, message becomes visible again after *visibility timeout*.

---

# ğŸ” **Important Concepts**

### ğŸ“¨ **Message**

* Max size: **256 KB**
* Can be JSON, text, XML, etc.

### â²ï¸ **Visibility Timeout**

* Time during which a message stays **hidden** after being read.
* Prevents multiple workers from processing the same message.

### ğŸ“… **Message Retention**

* How long SQS stores a message (1 min â†’ 14 days).

### ğŸ—³ï¸ **Dead Letter Queue (DLQ)**

Failed messages (not processed after X retries) go into a **DLQ** for debugging.

### ğŸ” **Long Polling**

* Waits until a message arrives (reduces empty responses).
* Cheaper & more efficient.

---

# ğŸ› ï¸ **Features of SQS**

### âœ”ï¸ **Decoupling**

Connect services without direct communication.

### âœ”ï¸ **Highly Scalable**

Handles **millions of messages per second** automatically.

### âœ”ï¸ **Durable**

Messages stored across **multiple AZs**.

### âœ”ï¸ **Secure**

Supports:

* IAM policies
* KMS encryption
* Private access via VPC Endpoint

### âœ”ï¸ **Fully Managed**

No servers, no maintenance.

---

# ğŸ¯ **When to Use SQS?**

* Microservices communication
* Order processing systems
* Video/image processing pipelines
* Logging & monitoring systems
* Asynchronous tasks
* Queue-based batch processing

---

# ğŸ§° **SQS Basic Commands (AWS CLI)**

```bash
# Create queue
aws sqs create-queue --queue-name MyQueue

# List queues
aws sqs list-queues

# Send message
aws sqs send-message --queue-url <URL> --message-body "Hello"

# Receive message
aws sqs receive-message --queue-url <URL>

# Delete message
aws sqs delete-message --queue-url <URL> --receipt-handle <handle>
```

---

# ğŸ“Œ **SQS Pricing (Simple Overview)**

* First **1 million requests free/month**
* After that pay per request (very cheap)
* FIFO queues cost slightly more

---

# ğŸ”„ **SNS vs SQS (Interview Notes)**

| Feature       | SNS                  | SQS                    |
| ------------- | -------------------- | ---------------------- |
| Type          | Pub/Sub              | Message Queue          |
| Delivers To   | Multiple subscribers | One consumer at a time |
| Message Order | No                   | FIFO (optional)        |
| Use Case      | Broadcast            | Decoupling workers     |

---

# ğŸ§ª **Example Use Case (Simple)**

### ğŸ›ï¸ **E-commerce Order Workflow**

1. User places an order
2. Backend sends order message â†’ **SQS**
3. Worker reads message
4. Worker processes payment, inventory, email
5. Message deleted

â¡ï¸ System is scalable + reliable.

---

# ğŸ“ **Final Summary**

* SQS = **Scalable message queue**
* Two types: **Standard** & **FIFO**
* Key elements: Visibility Timeout, DLQ, Long Polling
* Ideal for decoupled, async systems
* Cheap, secure, fault-tolerant

# ğŸ“¦ AWS SQS â€“ Simple Hands-On Lab

This lab teaches complete beginners how to use **Amazon Simple Queue Service (SQS)** using only the AWS Console.
You will **create a queue â†’ send a message â†’ receive it â†’ delete it**.

---

## âœ… Prerequisites

* AWS account
* Access to AWS Console

---

## ğŸŸ© Step 1 â€” Open SQS

1. Login to AWS Console
2. Search for **SQS**
3. Open **Simple Queue Service**

---

## ğŸŸ© Step 2 â€” Create a Queue

1. Click **Create queue**
2. Select **Standard queue**
3. Enter queue name:

   ```
   my-demo-queue
   ```
4. Scroll down â†’ Click **Create queue**

âœ” The queue is created successfully.

---

## ğŸŸ© Step 3 â€” Send a Message

1. Open your queue: **my-demo-queue**
2. Click **Send and receive messages**
3. In the **Message body**, type:

   ```
   Hello from SQS
   ```
4. Click **Send message**

âœ” Message sent successfully.

---

## ğŸŸ© Step 4 â€” Receive the Message

1. In the same window, click **Poll for messages**
2. Wait for the message to appear
3. Click the message to view its content

âœ” You have received your message.

---

## ğŸŸ© Step 5 â€” Delete the Message

1. Select the message
2. Click **Delete**
3. Confirm the deletion

âœ” Your message has been removed from the queue.

---

## ğŸŸ© Step 6 â€” Clean Up

To avoid keeping unused resources:

1. Go back to the SQS main page
2. Select **my-demo-queue**
3. Click **Delete queue**

âœ” Queue deleted.

---

## ğŸ‰ Lab Completed!

You successfully learned how to:

* Create an SQS queue
* Send a message
* Receive & view the message
* Delete the message
* Delete the queue
---

# ğŸŒ **AWS CORS â€“ Cross-Origin Resource Sharing**

## ğŸ“˜ **What is CORS?**
![Screenshot](https://github.com/shyamdevk/AWS-Concepts-Labs/blob/images/cors.png)

**CORS (Cross-Origin Resource Sharing)** is a browser security feature that decides **which websites are allowed to access your AWS resources** (like S3, API Gateway, CloudFront).

ğŸ‘‰ If your frontend and backend are on **different domains**, the browser checks CORS.

---

# ğŸ” **Why CORS Exists?**

Browsers block requests between different websites to protect users from malicious sites.
So AWS resources must explicitly say:

> **â€œYes, this website is allowed to access me.â€**

---

# ğŸŸ¦ **When Does CORS Trigger?**

CORS is checked when:

* `frontend.com` â†’ calls â†’ `api.com`
* `localhost:3000` â†’ calls â†’ AWS API Gateway
* CloudFront â†’ loads image from S3
* Any **cross-domain** request happens

If CORS is not allowed â†’ browser blocks.

---

# ğŸ“Œ **Important CORS Concepts**

### **1. Origin**

Origin = Protocol + Domain + Port
Example:

```
https://example.com:443
```

### **2. Access-Control-Allow-Origin**

Specifies **which websites** can access the resource.

Example (allow one site):

```
Access-Control-Allow-Origin: https://myapp.com
```

Allow all sites:

```
Access-Control-Allow-Origin: *
```

### **3. Access-Control-Allow-Methods**

Allowed HTTP methods:

```
GET, POST, PUT, DELETE, OPTIONS
```

### **4. Access-Control-Allow-Headers**

What headers the frontend can send:

```
Content-Type, Authorization
```

### **5. Preflight Request**

Before sending actual data, browser sends:

```
OPTIONS request
```

to check if the server allows it.

If server responds with proper CORS headers â†’ request continues.

---

# ğŸ› ï¸ **CORS in AWS Services**

## âœ”ï¸ **1. S3 (Static Websites, Images, Files)**

To allow any website to access S3 objects:

```xml
<CORSRule>
  <AllowedOrigin>*</AllowedOrigin>
  <AllowedMethod>GET</AllowedMethod>
  <AllowedHeader>*</AllowedHeader>
</CORSRule>
```

If you want ONLY your site:

```xml
<CORSRule>
  <AllowedOrigin>https://mywebsite.com</AllowedOrigin>
  <AllowedMethod>GET</AllowedMethod>
  <AllowedHeader>*</AllowedHeader>
</CORSRule>
```

---

## âœ”ï¸ **2. API Gateway (Frontend â†’ API Calls)**

When frontend calls API Gateway, you must enable CORS.

Typical API Gateway response headers:

```
Access-Control-Allow-Origin: *
Access-Control-Allow-Methods: GET,POST,OPTIONS
Access-Control-Allow-Headers: Content-Type
```

API Gateway handles OPTIONS (preflight) automatically if CORS is enabled.

---

## âœ”ï¸ **3. CloudFront (CDN for S3/API)**

CloudFront must forward these headers to origin:

```
Origin
Access-Control-Request-Headers
Access-Control-Request-Method
```

Otherwise CORS fails even if S3/API is configured correctly.

---

# ğŸ¯ **Simple Example to Understand**

### Frontend:

```
http://localhost:3000
```

### API (AWS):

```
https://abc123.execute-api.ap-south-1.amazonaws.com
```

Since domains are different â†’ Browser blocks by default.

To allow access, API must return:

```
Access-Control-Allow-Origin: http://localhost:3000
```

Now browser allows the request.

---

# âš ï¸ **Common CORS Errors**

| Error                                     | Meaning                                      |
| ----------------------------------------- | -------------------------------------------- |
| **No Access-Control-Allow-Origin header** | CORS not enabled or wrong domain             |
| **Blocked by CORS policy**                | Browser rejected the request                 |
| **Preflight request failed (OPTIONS)**    | Backend did not respond correctly to OPTIONS |

---

# ğŸ§  **Super Simple Summary**

* CORS = Browser permission system
* AWS services must say **which websites can access them**
* Used in **API Gateway, S3, CloudFront**
* Without CORS â†’ Browser blocks request
* Always configure correct **origin, methods, headers**

---

# ğŸ§ª **LAB: Access S3 Image Using CORS + Load on Button Click**

## ğŸ¯ **Goal**

Set up an S3 bucket with correct **CORS**, **permissions**, and **public access** so a simple `index.html` file can load an image from S3 **only after pressing a button**.

---

# âœ… **Step 1: Create S3 Bucket**

1. Go to **AWS Console â†’ S3**
2. Click **Create bucket**
3. Bucket name:

   ```
   my-cors-demo-bucket-009
   ```
4. Leave all default settings
5. Click **Create bucket**

---

# âœ… **Step 2: Upload Image**

1. Open the bucket
2. Click **Upload**
3. Choose your file, example:

   ```
   image.png
   ```
4. Click **Upload**

---

# âœ… **Step 3: Fix Access Denied (Make Objects Public)**

### ğŸ”¹ Turn OFF Block Public Access

Go to:

**Bucket â†’ Permissions â†’ Block Public Access â†’ Edit**

Turn off:

* Block all public access
* Block public ACLs
* Block public bucket policies

Save.

---

### ğŸ”¹ Add Public Read Bucket Policy

Go to:

**Bucket â†’ Permissions â†’ Bucket Policy â†’ Edit**

Paste:

```json
{
  "Version": "2012-10-17",
  "Statement": [
    {
      "Sid": "AllowPublicRead",
      "Effect": "Allow",
      "Principal": "*",
      "Action": "s3:GetObject",
      "Resource": "arn:aws:s3:::my-cors-demo-bucket-009/*"
    }
  ]
}
```

Save changes.

---

# âœ… **Step 4: Add Correct JSON CORS Configuration**

Go to:

**Bucket â†’ Permissions â†’ CORS Configuration â†’ Edit**

Paste this:

```json
[
  {
    "AllowedHeaders": ["*"],
    "AllowedMethods": ["GET"],
    "AllowedOrigins": ["*"],
    "ExposeHeaders": []
  }
]
```

âœ” Fixes CORS issues
âœ” Lets any frontend load GET objects

---

# âœ… **Step 5: Test S3 URL**

Open your uploaded image:

```
https://my-cors-demo-bucket-009.s3.amazonaws.com/image.png
```

If the image displays â†’ permissions and CORS are correct.

---

# âœ… **Step 6: Create index.html (Load Image on Button Click)**

Create a file named **index.html**:

```html
<!DOCTYPE html>
<html>
<head>
    <title>Load S3 Image on Button Click</title>
</head>
<body style="font-family: Arial; text-align: center; margin-top: 50px;">

    <h2>Load Image from S3 using Button</h2>

    <button onclick="loadImage()" style="padding: 10px 20px; font-size: 16px;">
        Load Image
    </button>

    <br><br>

    <img id="s3Image" src="" alt="Image will load here" width="300"
         style="display:none; border:1px solid #ddd; padding:10px;">

    <script>
        function loadImage() {
            const imageUrl = "https://my-cors-demo-bucket-009.s3.amazonaws.com/image.png";
            const img = document.getElementById("s3Image");

            img.src = imageUrl;
            img.style.display = "block";
        }
    </script>

</body>
</html>
```

---

# âœ… **Step 7: Run the Test**

1. Open `index.html` in your browser
2. Click **Load Image**
3. You should now see the S3 image appear without errors

---
!

## ğŸ“˜ **VPN in VPC**

A **VPN (Virtual Private Network)** in AWS securely connects your **on-premises datacenter** or **office network** to your **AWS VPC** using encrypted tunnels over the internet.
This allows both networks to communicate **as if they were within the same private network**.

---

## ğŸ§± **Key Components**

### **1ï¸âƒ£ VPC**

Your private network inside AWS.

### **2ï¸âƒ£ Virtual Private Gateway (VGW)**

* AWS-side VPN endpoint
* Must be **attached to your VPC**

### **3ï¸âƒ£ Customer Gateway (CGW)**

* Represents your on-premises router/firewall
* Requires a **public IP address**

### **4ï¸âƒ£ VPN Connection**

* Creates the secure IPsec tunnel between CGW â†” VGW
* AWS provides **two tunnels** for high availability

---

## ğŸŒ **How VPN Works (Simple Flow)**

1. Create a **Virtual Private Gateway (VGW)**
2. Attach the VGW to your **VPC**
3. Create a **Customer Gateway (CGW)** using your routerâ€™s public IP
4. Create a **VPN Connection** linking VGW and CGW
5. Download VPN configuration and apply it to your on-prem router
6. Traffic starts flowing **securely** through encrypted tunnels

---

## ğŸ”‘ **Why Use VPN in VPC?**

* Secure communication between **AWS and on-premises**
* Easy and fast to set up
* Low cost compared to Direct Connect
* Provides **hybrid cloud** capability

---

## ğŸš€ **Types of VPN in AWS**

### **ğŸ”¹ Site-to-Site VPN**

Connects entire on-prem network to AWS VPC
(Most commonly used)

### **ğŸ”¹ Client VPN**

Allows individual users to connect securely from laptops or mobile devices.

### **ğŸ”¹ AWS CloudHub**

Used to connect multiple branch locations together using AWS.

---

## âœ”ï¸ **Benefits**

* Encrypted traffic over internet
* Two tunnels = High availability
* Low cost and quick setup
* Works with most routers

---

## âš ï¸ **Limitations**

* Depends on internet reliability
* Higher latency compared to Direct Connect
* Throughput limits (~1.25 Gbps)

---

## ğŸ“ **Short Summary for Quick Revision**

```
VPN in VPC provides a secure, encrypted tunnel between on-premises networks and AWS VPC using a Virtual Private Gateway and Customer Gateway. It enables hybrid cloud connectivity, supports two tunnels for redundancy, and is cost-effective and easy to configure.
```

# **ğŸ›¡ï¸ AWS WAF â€“ Web Application Firewall**

Amazon Web Application Firewall (**AWS WAF**) protects your **web applications** from common internet attacks.
Think of it as a **security guard standing in front of your website**, checking every request and blocking the bad ones.

---

## ğŸ“Œ What is AWS WAF?

AWS WAF (Web Application Firewall) helps protect:

* Web applications
* APIs
* Websites

by filtering incoming traffic and blocking harmful requests.

---

## ğŸ¯ Why Use AWS WAF?

AWS WAF protects your application from:

* âŒ **SQL Injection (SQLi)**
* âŒ **Cross-Site Scripting (XSS)**
* âŒ **Bad Bots**
* âŒ **DDoS (Layer 7)**
* âŒ **IP-based attacks**
* âŒ **Suspicious or unwanted traffic**

âœ” Helps improve security
âœ” Maintains availability
âœ” Protects your APIs and websites

---

## ğŸ—ï¸ Where Can You Use AWS WAF?

AWS WAF can be attached to:

* ğŸŒ **CloudFront** (CDN)
* âš–ï¸ **Application Load Balancer (ALB)**
* ğŸ”Œ **API Gateway**
* ğŸ“¡ **AWS AppSync (GraphQL)**

---

## ğŸ§± Core Components of AWS WAF

### 1ï¸âƒ£ **Web ACL (Access Control List)**

This is the **main firewall**.
Contains all rules to ALLOW, BLOCK, or COUNT requests.

### 2ï¸âƒ£ **Rules**

Define what traffic to block or allow.
Examples:

* Block IPs
* Allow internal IPs
* Detect SQLi / XSS
* Filter based on headers / URIs

### 3ï¸âƒ£ **Rule Groups**

A collection of rules bundled together.
You can use:

* **AWS Managed Rule Groups** (recommended)
* **Custom Rule Groups**

### 4ï¸âƒ£ **Managed Rules**

Prebuilt protection by AWS including:

* SQL Injection protection
* XSS protection
* Bad Bot detection
* Known attack signatures

Easy to use: **just enable them**.

---

## ğŸ” How AWS WAF Works (Simple Flow)

1. A user sends a request to your application
2. Request first goes through **AWS WAF**
3. WAF checks rules inside the **Web ACL**
4. WAF decides:

   * âœ” **Allow**
   * âŒ **Block**
   * ğŸ“Š **Count (log only)**

---

## ğŸ§ª Examples of Common Rules

### âœ” Block specific IPs

Example: Block an attackerâ€™s IP.

### âœ” Allow only office IPs

Helpful for internal apps.

### âœ” Block SQL Injection automatically

Use AWS managed rules.

### âœ” Rate Limiting

Example: Block users sending
**more than 100 requests in 5 minutes**.

---

## ğŸ’² AWS WAF Pricing (Simple)

You pay for:

* Number of **Web ACLs**
* Number of **Rules**
* Number of **Requests inspected**

No upfront cost â†’ Pay only for what you use.

---

## ğŸ“Š Monitoring AWS WAF

You can monitor traffic using:

* **CloudWatch Metrics**
* **AWS WAF Logs**
* **Kinesis**
* **S3 log storage**
* **CloudWatch Dashboards**

You can see:

* Blocked Requests
* Allowed Requests
* Which rule triggered
* Traffic patterns

---

## ğŸ§  Advantages of AWS WAF

* Easy to setup
* Protects from common attacks
* Auto scales with your traffic
* Integrates well with CloudFront, ALB, API Gateway
* Managed rules save time
* Improves website & API security

---

## ğŸ“Œ Quick Summary

AWS WAF protects your web applications by:

* Checking incoming traffic
* Blocking harmful requests
* Allowing only safe traffic

It uses **Web ACLs** + **Rules** and integrates with **CloudFront, ALB, and API Gateway**.
Easy to use, powerful, and scalable.

---

# ğŸ›¡ï¸ AWS WAF Hands-On Lab (Attach to ALB with Custom Rules)

This lab walks you through creating an **AWS WAF Web ACL**, adding **custom rules**, creating an **IP Set**, and attaching WAF to an **Application Load Balancer (ALB)**.

> ğŸ”” **Note:**
> VPC, EC2 instance, User Data web server, and ALB creation are **already covered**.
> This focuses **only on AWS WAF steps**.

---

## ğŸ“Œ **Lab Overview**

You will create:

* ğŸŒ **Web ACL**
* ğŸ“˜ **IP Set** (for your IP address)
* ğŸš« **Block Rule**
* ğŸ” **Captcha Rule**
* ğŸ”— **Attach WAF to ALB**

---

# ğŸŸ¦ 1. Open AWS WAF Console

1. Go to AWS Console
2. Search **WAF**
3. Open **AWS WAF & Shield**

---

# ğŸŸ© 2. Create an IP Set (Add Your IP)

This IP Set will contain **your public IP** â†’ so you can be allowed.

1. Left menu â†’ **IP addresses**
2. Click **Create IP set**
3. Enter:

   * **Name:** `My-IP-Set`
   * **Region:** Same as ALB
4. Under **IP addresses**, enter your IP:

   ```
   <your-public-ip>/32
   ```

   Example:

   ```
   49.37.171.28/32
   ```
5. Click **Create IP set**

âœ” Your IP Set is now ready.

---

# ğŸŸ§ 3. Create a Web ACL

1. Left menu â†’ **Web ACLs**
2. Click **Create web ACL**
3. Enter:

   * **Name:** `My-Web-ACL`
   * **Region:** Same as ALB
4. **Resource Type:**

   ```
   Application Load Balancer
   ```
5. Select **your ALB**
6. Click **Next**

---

# ğŸŸ¥ 4. Add Rules to Web ACL

You will add three rules:

1. **Allow your IP**
2. **Block a sample IP range**
3. **Captcha for unknown/high-rate traffic**

---

## âœ³ï¸ Rule 1 â€” Allow Your IP

1. Click **Add rule â†’ Add my own rules and rule groups**
2. Select **Rule builder**
3. Rule name: `Allow-My-IP`
4. Rule type: **IP match**
5. Choose **IP set** â†’ `My-IP-Set`
6. Action â†’ **Allow**
7. Save rule

âœ” You will always be allowed.

---

## âœ³ï¸ Rule 2 â€” Block a Test IP Range

(Use ANY IP range for testing.)

1. Add rule â†’ Rule builder
2. Rule name: `Block-Test-IP`
3. Match type: **IP match**
4. Create new IP set (example):

   ```
   1.1.1.0/24
   ```
5. Action â†’ **Block**
6. Save rule

âœ” Any request from that range will be blocked.

---

## âœ³ï¸ Rule 3 â€” Captcha High Request Traffic

1. Add rule â†’ **Rule builder**
2. Name: `Captcha-Unknown-IPs`
3. Rule type: **Rate-based rule**
4. Limit:

   ```
   100 requests per 5 minutes
   ```
5. Action â†’ **Captcha**
6. Save rule

âœ” High-frequency traffic will get a CAPTCHA.

---

# ğŸŸª 5. Set Rule Priority (ORDER IS IMPORTANT)

Drag and arrange rules:

```
1ï¸âƒ£ Allow-My-IP
2ï¸âƒ£ Block-Test-IP
3ï¸âƒ£ Captcha-Unknown-IPs
```

Default Action â†’ **Allow**
(Recommended for labs)

---

# ğŸŸ¦ 6. Review & Create

1. Click **Next**
2. Review all rules
3. Click **Create Web ACL**

âœ” WAF is now attached to your ALB with all rules active.

---

# ğŸŸ¨ 7. Testing the WAF Rules

### âœ… Test Allow Rule

Open your ALB DNS in your browser:

```
http://<ALB-DNS>
```

Your IP should load the website normally.

---

### âŒ Test Block Rule

Try accessing from:

* VPN
* Proxy
* Mobile hotspot
* Online IP testing tool

A blocked IP should receive **403 Forbidden**.

---

### ğŸ” Test Captcha Rule

Refresh your browser very fast or use a simple curl loop â†’
You should eventually see a **CAPTCHA challenge**.

---

# ğŸ‰ **Lab Completed Successfully!**

You have implemented:

* âœ” IP Set
* âœ” Web ACL
* âœ” Allow, Block & Captcha rules
* âœ” WAF attached to ALB
* âœ” Practical testing

---










